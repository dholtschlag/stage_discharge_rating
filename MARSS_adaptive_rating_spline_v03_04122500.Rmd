---
title: "Adapting rating curves for persistent changes in stage-flow relations and characterizing uncertainties of streamflow records with discrete measurements"
author: "David J Holtschlag"
date: "`r format(Sys.Date(), '%A %b %d, %Y') `"
output: 
  html_document:
    toc: true
    toc_depth: 4
  always_allow_html: yes
bibliography: bibliography.bib
---

## Abstract

An adaptive stage-flow estimation approach is developed to track persistent changes in the relation between stage (water-surface elevation) and flow (streamflow discharge) at a stratagem. The approach is initialized by estimating a cubic spline regression of the stage-flow relation within a generalized additive modelling (GAM) framework. The parameters of the cubic spline regression can be estimated from an extended stage-flow rating table, or from pairs of discrete stage and flow measurements that adequately define the stage domain of interest. In addition to these parameters, the basis vectors derived from the stage values and used to develop the regression or from any other set of stage measurements can be extracted or generated from the GAM object. Then, process and measurement error variances of a state-space model are estimated using available discrete measurement data. The fitted state-space model can then be used to update regression parameters with data from each subsequent discrete measurement. The resulting changes in regression parameters and corresponding stage-flow relation can be determined after each discrete measurement.  Finally, Kalman filtering can be used with time series of stage values to compute the magnitude and uncertainty of a streamflow time series. The approach is demonstrated with data from the U.S. Geological Survey streamgage 04122500 Pere Marquette River at Scottville, Mich.  Extension of this approach to track intermittent changes, associated with variable ice-backwater for example, would require a multivariate analysis involving a streamflow network that is beyond the scope of this report. 

## Background

The U.S. Geological Survey (USGS) computes records of streamflow at about 8,500 active streamgages throughout the United States. Streamgages measure flow from the upstream basin, which is generally topographically defined by a watershed.  Computations are commonly based on continual measurements of stage at 10- to 60-minute intervals. The stage data is used to compute corresponding values of flow based on a empirical relation between stage and flow commonly referred to as a rating curve or table. The rating describes a monotonically increasing relation between stage and flow. This rating is developed and maintained on the basis of discrete, contemporaneous measurements of stage and flow that span the typical range of flow conditions at the streamgage. Discrete measurements require a field visit to the streamgage, which can be a major element in the cost of streamgage operation. 

The stage-flow relation can change gradually over time due to persistent changes in the channel or overbank geometry and hydraulic characteristics. Alternatively, this relation can change abruptly owing to intermittent effects, such as increased backwater associated with aquatic plant growth or ice formation. Once the cause of the intermittent changes are no longer present, the stage-flow relation may revert to nominal conditions, consistent with possible persistent changes at the stream site.  Commonly both persistent and intermittent changes occur in the stage-flow rating.  The distinction between persistent and intermittent changes is somewhat arbitrary, but practically determined by the frequency of discrete measurements. Abrupt intermittent changes, such as ice backwater effects, can occur on a time scale of hours to days during periods when no discrete flow measurements occur to identify the onset, cessation, or magnitude of backwater associated with these events. 

### Purpose and Scope

The purpose of this paper is to outline an approach for automatically adapting streamflow rating curves for persistent changes in stage-flow relations based on discrete stage-flow measurements. The approach also enables the estimation of the magnitudes and uncertainties of unit streamflow records. A persistent change refers to a gradual change in rating conditions where the frequency of discrete measurements are adequate to approximate the beginning and ending of the changes in rating conditions. The adaptive approach can be applied in real-time by considering only past or current discrete measurements, or offline, considering discrete flow measurements before and after the time of estimation. An implementation strategy and example application are provided, while recognizing that refinements and conventions will likely be needed for routine applications.  

In contrast to persistent changes, intermittent changes represent sudden changes in rating conditions that may be associated with transient effects like those changes in rating conditions associated with backwater due to ice formation in the channel. Tracking intermittent changes requires more precise information on the timing of the onset and cessation of the intermittent effects than is generally possible from discrete flow measurements.  Intermittent changes may benefit from analysis of multiple streamgages in a network, but is beyond the scope of this study. 


```{r setup, include=FALSE}
# Libraries needed in the analysis are loaded here
library( "rethinking" )
options(mc.cores = parallel::detectCores())
suppressPackageStartupMessages(library(dataRetrieval))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(ggthemes))
suppressPackageStartupMessages(library(splines))
suppressPackageStartupMessages(library(mgcv))
suppressPackageStartupMessages(library(fitdistrplus))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(kableExtra))
suppressPackageStartupMessages(library(ggrepel))
suppressPackageStartupMessages(library(ggcorrplot))
# strcmp and other Matlab like functions
suppressPackageStartupMessages(library(pracma))
# Package expss contains the function vlookup
suppressPackageStartupMessages(library(expss))
# Package to plot distribution
suppressPackageStartupMessages(library(ggfortify))
# Multivariate Autoregressive State Space Model
suppressPackageStartupMessages(library(MARSS))
suppressPackageStartupMessages(library(matrixcalc))
# The broom package takes the messy output of built-in functions in R, such as lm, nls, or t.test, and turns them into tidy data frames.
suppressPackageStartupMessages(library(broom))
suppressPackageStartupMessages(library(gganimate))
suppressPackageStartupMessages(library(gifski))
# scales is used in density plot
suppressPackageStartupMessages(library(scales))
suppressPackageStartupMessages(library(ggmap))
suppressPackageStartupMessages(library(ggsn))
suppressPackageStartupMessages(library(sf))
suppressPackageStartupMessages(library(usmap))
suppressPackageStartupMessages(library(FAdist))
knitr::opts_chunk$set(echo = FALSE, fig.width = 8)
```



```{r specify_gage, echo = FALSE, results = 'hide' }

# The starting and ending dates of the model
#   Based on the beginning of unit stage date and endin on the first flow measurement of water year 2020
date_beg_model  <- as.Date( '1989-09-30', format = '%Y-%m-%d' ) 
date_end_model  <- as.Date( '2019-10-08', format = '%Y-%m-%d' )

# initialize counter for figures
fig_no <- 0
tab_no <- 0

# Retrieve gage info for specified site Number
site_no    <- '04122500'

# Used in accessing site_info
site_file  <- paste0('site_', site_no, '.RData')

if( file.exists(site_file)){
  # print(paste('Loading site_info for', site_no, 'from RData file.'))
  load(site_file)
} else {
  # print(paste('Retrieving site_info for', site_no, 'from NWIS' ))
  site_info  <- readNWISsite(site_no)

  # Standardize field names
  site_info  <- renameNWISColumns(site_info)
  # Standarize capitalization of site name
  # site_info$station_nm <- str_to_title( site_info$station_nm )
  site_info$station_nm <- "Pere Marquette River At Scottville, Mich."
  save(site_info, file = site_file)
}

```



```{r show_site_info, fig.height = 2, warning = 'hide', results = 'hide', eval = FALSE }

site_info %>% 
  rename( drain_area_mi2 = drain_area_va,
          latitude       = dec_lat_va,
          longitude      = dec_long_va,
          altitude_ft    = alt_va ,
          altitude_datum = alt_datum_cd) %>% 
  dplyr::select( site_no, station_nm, drain_area_mi2, latitude, longitude, altitude_ft, altitude_datum) %>% 
  kable( caption = paste0('Table ',tab_no,'. Summary streamgage information' )) %>% 
  kable_styling()


```
### Study Area

USGS streamgage 04122500 Pere Marquette River at Scottville, Mich. was selected for this study. (fig. 1). The Pere Marquette River drains a basin of 681 mi^2^ in the west central lower peninsula of Michigan. The basin is generally forest covered, which includes parts of the Huron-Manistee National Forest.  The city of Scottville, population 1,214, and the village of Baldwin, population 1,208,  (https://factfinder.census.gov/faces/nav/jsf/pages/community_facts.xhtml, accessed Feb. 1, 2020), are the primary population centers in the basin.  Streamflow has been computed continuously at the site starting in August 1939 and was active at the time of this paper (October 2020).

The Pere Marquette streamgage was selected because it has an extended period of data to support the analysis.  Electronically accessible records include unit (shorter than daily interval) stage data beginning in October 1989, to present. Daily mean streamflow data is available from April 1939 to present. Paired stage-flow (discrete) measurements obtained during field visits is available electronically beginning in August 1985. In addition, extended (0.01-ft interval) stage-flow rating tables (ratings), used to compute unit flow values, are electronically accessible.  For this study, ratings 18, 19, 20, and 21, were used, corresponding to the period from October 1986 to October 2019. These rating show a persistent (and conspicuous) trend that generally enabled a lower stage to pass a higher flow than earlier stage-flow relations generally indicate. In particular, rating 21 passes 55.1 percent more flow than rating 18 at 1.4 ft of stage. This increase diminishes to 12.3 percent more flow at 8.0 ft of stage.  

Persistent changes in stage-flow relation at 04122500 Pere Marquette River at Scottville, Mich., may be related to streambed stability. In particular, the sand channel has shown considerable scour potential. For example, on Sept. 13, 1986, a high flow of 6,440 ft^3^/s was measured at the streamgage, with a maximum local streambed scour of 1.55 ft. Four days later, a second discrete flow measurement of 2,610 ft^3^/s was obtained in which a maximum local streambed scour of 4.06 ft was measured [@holtschlag1998]. The utility of the proposed approach for tracking changes in the stage-flow relation, however, is not thought to require such a conspicuous trend. In addition to the persistent trend, intermittent seasonal ice affects periodically increases the stage needed to pass a given flow than during open-water conditions.  
 

```{r register_key, echo = FALSE,  results = 'hide', message = 'hide', warning = 'hide'}

# this sets your google map for this session
# Read google key from file
# google_key <- read_file('maps/google_key.txt')

# Register the key and delete it following registry
# register_google(key = google_key)
# rm('google_key')

# check if key is saved
# has_google_key()

# Set up bounding box for map

# site_map <- get_map( location = c(lon = site_info$dec_long_va + 0.10, lat = site_info$dec_lat_va),
#                      zoom = 9, source = 'google', maptype = "terrain")
# 
# write_rds(site_map, path = "C:/Home/projects/spline_rating_curves/stage_discharge_rating/maps/site_map")

suppressMessages(map <- read_rds(path = "C:/Home/projects/spline_rating_curves/stage_discharge_rating/maps/site_map"))

invisible(watershed    <- st_read("C:/Home/ws_012/fhwa_flood_regions/gis/shapefiles/04122500.shp"))
watershed_df <- data.frame( lon = st_coordinates(watershed)[,1],
                           lat = st_coordinates(watershed)[,2]) 
```


```{r plot_site_map, fig.height = 7, fig.width = 7, message = FALSE, warning = 'hide' }
 fig_no <- fig_no + 1

# Site map with streamgage and drainage basin shown
vicinity <- map %>% 
  ggmap() +
  geom_point( data = data.frame( lon = site_info$dec_long_va, lat = site_info$dec_lat_va),
              aes( x = lon, y = lat), color = 'red', size = 3) +
  geom_polygon( data = watershed_df, aes( x = lon, y = lat), color = 'lightgrey', alpha = 0.15 ) +
  xlab( 'Longitude' ) + 
  ylab( 'Latitude') +
  scalebar(x.min = -86.95622, x.max = -85.29841, y.min =  43.40782, y.max =  44.5, 
           transform = TRUE, dist_unit = 'mi', dist = 10, location = 'bottomleft',
           model = "GRS80", height = 0.02, st.size = 3, st.dist = .015,
           border.size = 1, box.fill = c('black', 'white')) +
  annotate('text', x = -85.88, y = 43.85, label = 'Pere Marquette Basin' ) +
  annotate('text', x = -86.28, y = 43.99, label = '04122500') +
  ggtitle( paste0('Figure ', fig_no, '. U.S. Geological Survey streamgage 04122500 Pere Marquette \nRiver at Scottville, Mich. and drainage basin'))

mi_map <- map_data('state')

mi_inset <-mi_map %>% 
  dplyr::filter( region == 'michigan') %>% 
  ggplot( aes( x = long, y = lat, group = group)) +
  geom_polygon( fill = 'black') +
  geom_point( data = data.frame( long = site_info$dec_long_va, lat = site_info$dec_lat_va),
              aes( x = long, y = lat, group = NA), color = 'red', size = 2) + 
  xlab('') +
  ylab('')


vicinity + inset(grob = ggplotGrob(mi_inset), xmin = -86.85, xmax = -86.4, 
                                                      ymin =  44.25, ymax =  44.55)


```


## Data Components

This section discusses data required for implementation of the adaptive stage-flow rating approach. Continual streamflow data are commonly computed on the basis of continual stage data, and an empirical relation between stage and flow. The continual intervals are generally less than or equal to an hour in length, and are referred to as unit data.  The relation between stage and flow is based on periodic discrete stage and flow measurements obtained during a field visit to the streamgage. A set of discrete measurements is used to manually define a curvilinear relation between stage and flow over an extended stage range. The stage-flow relation is commonly referred to as a rating curve or table. Discrete measurements continue throughout the period of streamgage operation to confirm, update, extend, and revise the stage-flow relation as needed accurately compute streamflow. Major changes in the stage-flow relations are indicated by (generally integer) changes in the rating number.   

Several data components are critical in computing unit streamflow, and derivative products, such as daily (mean) streamflow. Daily streamflow is the primary streamflow statistic used in many water-resource applications. Daily streamflow is commonly used, for example, to compute flow-duration and high- and low-frequency characteristics widely used in design and decision making. Therefore, daily streamflow data were the first streamflow statistic to be accessible electronically and generally has the longest period of record.  

Historically, unit stage and flow values have been considered ancillary data of secondary importance to daily streamflow. High cost of electronic storage of these data were prohibitive. More recently, however, both unit stage and unit flow data has been stored in accessible formats along with information on discrete stage-flow measurements. Ready access to these data have been instrumental in developing the analysis presented in this paper. 

### Daily Streamflow

Daily mean streamflow data for the Pere Marquette River were obtained for the period of record using the USGS National Water Information System (NWIS) by use of the R package 'dataRetrieval' [@DeCicco2019]. Some of the earlier ancillary data used in computing daily mean flows, however, is only available from archived paper records. In particular, unit stage data and discrete flow measurement data are generally available for Pere Marquette River in electronic format since `r format(date_beg_model, '%b %d, %Y')`. The most recent data used in the analysis was `r format(date_beg_model, '%b %d, %Y')`. In this paper, the period of electronic data availability is referred to as the period of analysis (POA). Data summaries presented in the following sections are restricted to this period.



```{r pub_daily_flow}
# Load daily flows to estimate missing daily mean stage 
if( file.exists('flow_daily_pub.RData')){
  # print('Loading published daily_means from RData file.')
  load('flow_daily_pub.RData')
} else {
  # print('Retrieving daily flow from NWIS')
  flow_daily_pub <- readNWISdv( site_no, parameterCd = '00060', startDate = date_beg_model,
                             endDate = date_end_model)
  # Standardize names
  flow_daily_pub <- renameNWISColumns( flow_daily_pub )
  save(flow_daily_pub, file = 'flow_daily_pub.RData')
}

flow_hpdi <- HPDI( flow_daily_pub$Flow, prob = 0.95 )

```

***  

#### Frequency-Magnitude Characteristics of Daily Flows  

The probability density curves describes the frequency characteristics of daily flow magnitudes.  Daily flows at Pere Marquette River during the period of analysis ranged from `r flow_hpdi[[1]]` and `r flow_hpdi[[2]]` ft^3^/s, 95-percent of the time.  The minimum and maximum daily flows during this period were `r min(flow_daily_pub$Flow)` and `r max(flow_daily_pub$Flow)`, respectively. The mean flow was 787 ft^3^/s. The probability densities of the flows are asymmetric (right skewed). The natural logarithms of flows, however, are consistent with a three parameter gamma distribution (fig. 2). This distribution is an important consideration in specifying a data transformation to track changes in stage-flow relations.   

```{r prob_den_flow, warning = FALSE }
# Estimate parameters for lgamma3
gam3_parm <- fitdist(log(flow_daily_pub$Flow), 'gamma3', start = list(shape = 1, scale = 1, thres = 1),
        upper = c(Inf, Inf, min(log(flow_daily_pub$Flow))))

gam3_seq <- seq(gam3_parm$estimate[3], max(log(flow_daily_pub$Flow)), by = 0.02)
gam3_den <- dgamma3(gam3_seq, shape = gam3_parm$estimate[1],
                    scale = gam3_parm$estimate[2], thres = gam3_parm$estimate[3])
gam3_df  <- data.frame(gam3_seq, gam3_den)


fig_no <- fig_no + 1

# Plot the empirical density of log(Flow) with theoretical GAMMA3 Density 

flow_daily_pub %>% 
  ggplot( aes( Flow)) +
  geom_density( fill = 'lightgrey', alpha = 0.5 ) +
  theme_bw() +
  scale_x_continuous( trans = 'log', breaks = c( 300, 500, 1000, 2000, 3000, 4000, 5000), limits = c(300, 5000) ) + 
  geom_vline( xintercept =  mean(flow_daily_pub$Flow), linetype = 'dashed') +
  geom_vline( xintercept = c(345, 1460), linetype = 'dotted' ) +  
  annotate('text', x =  400, y = 0.925, label = '2.5% \nquantile \n = 403') +
  annotate('text', x = 2100, y = 0.925, label = '97.5% quantile = 1680' ) +
  annotate('text', x = 1000, y = 0.2, label = paste0('Mean = ', format(mean(flow_daily_pub$Flow), digits = 0 ))) +
  geom_line( data = gam3_df, aes( x = exp(gam3_seq), y = gam3_den), color = 'blue' ) +
  xlab('Flow, in cubic feet per second') +
  ylab('Probability density') +
  annotate('text', x = 350, y = 1.12, label = 'Theoretical \n Gamma Density', color = 'blue', size = 3) +
  # annotate('text', x = exp(7.65), y = 1.09, label = paste0('dgamma3( shape = ', format( gam3_parm$estimate[1], digits = 4),
  #                                   ', scale = ', format( gam3_parm$estimate[2], digits = 4),
  #                                   ', thres = ', format( gam3_parm$estimate[3], digits = 4),' )'), color = 'red', size = 3.8) +
  annotate('segment', x = 450, y = 1.10, xend = 570, yend = 1.10, color = 'red' ) +
  annotate('text', x = 1250, y = 0.10, label = 'Empirical Density', size = 3 ) +
  ggtitle( paste0( 'Figure ', fig_no, '. Distribution of daily flows at 04122500 Pere Marquette River at Scottsdale, \n Mich. based on data from ', format(date_beg_model, '%B %d, %Y'), ' to ', format(date_end_model, '%B %d, %Y')) ) 

```

***

### Discrete Stage and Flow Measurement Data

```{r read_discrete_meas_stage_flow, echo = FALSE,  warning = FALSE }

if( file.exists('discrete_meas.RData')){
  # print('Loading discrete flow measurement data from RData file.')
  load('discrete_meas.RData')
} else {
  # print('Retrieving daily flow from NWIS')
  discrete_meas   <- readNWISmeas(site_no, expanded = TRUE, convertType = TRUE)
  # Standardize field names
  discrete_meas  <- renameNWISColumns(discrete_meas)
  save(discrete_meas, file = 'discrete_meas.RData')
}

# Remove measurement number 474 measured Jan. 28, 1986, as outlier (indicate shore ice, qualifier 'fair')
discrete_meas <- discrete_meas[ -which( discrete_meas$measurement_nu == 474 ) , ]
#                           657 measured Dec. 11, 2013, as outlier (indicate shore ice, qualifier 'poor')
discrete_meas <- discrete_meas[ -which( discrete_meas$measurement_nu == 657 ) , ]

# Standardize attributes names for hydraulic control
control_type <- 
  recode_factor( discrete_meas$control_type_cd, 
                 'Clear'    = 'Clear Channel',
          'VegetationLight' = 'Light Vegetation',
          'DebrisLight'     = 'Light Debris',   
          'IceShore'        = 'Shore Ice',
          'DebrisModerate'  = 'Moderate Debris',
          'IceCover'        = 'Ice Cover', .ordered = TRUE ) 

# Add control type to data.frame
discrete_meas$control_type <- control_type


# Source 
# https://help.waterdata.usgs.gov/codes-and-parameters/discharge-measurement-quality-code
# ---------------------------------
# Code  Description
# ---------------------------------
# E     Excellent    The data is within 2% (percent) of the actual flow {95 percent of the time}
# G     Good         The data is within 5% (percent) of the actual flow
# F     Fair         The data is within 8% (percent) of the actual flow
# P     Poor         The data are >8% (percent) of the actual flow

discrete_meas <- discrete_meas %>% 
  dplyr::rename( 'qualifier' = 'measured_rating_diff') %>% 
  mutate( se_pct = case_when( qualifier == 'Excellent' ~  2.0,
                              qualifier == 'Good'      ~  5.0,
                              qualifier == 'Fair'      ~  8.0,
                              qualifier == 'Poor'      ~ 12.0),
          se_flow = se_pct/100 * discharge_va ) 


# Read rating history
rating_history <- read.csv( 'Data/04122500/rating_period_start_end.txt', sep = '\t', header = TRUE,
                            colClasses = c('numeric', 'Date', 'Date'), comment.char = '#')

# Rename discrete measurements accuracy and period of analysis
discrete_meas <- discrete_meas %>% 
  rename('stage_discrete_mea'  = 'gage_height_va',
         'flow_discrete_mea'   = 'discharge_va') %>% 
  filter(qualifier            != 'Unspecified' | qualifier == !is.na(qualifier)) %>%
  mutate('qualifier'           =  ordered(qualifier, levels = c('Excellent', 'Good', 'Fair', 'Poor')),
         'Date'                =  measurement_dt,
         'rating_no'    =  case_when( Date >= rating_history$start_date[1] & Date <  rating_history$end_date[1] ~ 18,
                                             Date >= rating_history$start_date[2] & Date <  rating_history$end_date[2] ~ 19,
                                             Date >= rating_history$start_date[3] & Date <  rating_history$end_date[3] ~ 20,
                                             Date >= rating_history$start_date[4] & Date <  rating_history$end_date[4] ~ 21),
         'period_of_analysis'  =  ifelse( Date >= date_beg_model & Date <= date_end_model, TRUE, FALSE)) %>% 
  dplyr::select( 'Date', 'measurement_nu', 'stage_discrete_mea', 'flow_discrete_mea', 'qualifier', 
                 'control_type', 'rating_no', 'period_of_analysis', 'se_pct', 'se_flow') %>% 
  addWaterYear()


lm_lflow <-  summary( lm( log10(discrete_meas$flow_discrete_mea) ~ discrete_meas$Date  ) )

lm_lstage <- summary( lm( log10(discrete_meas$stage_discrete_mea) ~ discrete_meas$Date ) )

```


Figure `r fig_no + 1` shows a time series plot of discrete flow and stage measurements during the period for which these data were electronically accessible. There are no apparent trends in the magnitudes of the logarithms of flows (*p* = `r format( lm_lflow$coefficients[2,4], digits = 4)`). There is, however, a statistically significant negative trend (*p* = `r format( lm_lstage$coefficients[2,4], digits = 4)`) in the logarithms of stage during the period. Given the apparent lack of trend in discrete flow values, the lowering of the minimum water levels may be the result of channel degradation. 


```{r plot_discrete_data, message = FALSE, fig.height = 6 }
# Plot discrete Flow and Stage
fig_no <- fig_no + 1
discrete_meas %>% 
  dplyr::select( Date, flow_discrete_mea, stage_discrete_mea ) %>% 
  dplyr::rename( Flow = flow_discrete_mea,
                 Stage = stage_discrete_mea ) %>% 
  gather( 'Parameter', 'Magnitude',  -Date ) %>% 
  ggplot( aes( x = Date, y = Magnitude, group = Parameter ) ) +
  geom_point( method = 'gam') +
  facet_grid( Parameter ~ ., scales = 'free_y' )  +
  theme_bw() +
  geom_smooth( method = 'lm') +
  scale_y_log10( ) +
  scale_x_date( breaks =        seq(as.Date("1985/1/1"), as.Date("2020/1/1"), by = "5 years"),
                labels = format(seq(as.Date("1985/1/1"), as.Date("2020/1/1"), by = "5 years"), '%Y')) +
  # geom_vline( xintercept = c(date_beg_model, date_end_model), linetype = 'dashed') +
  # geom_vline( xintercept = as.Date( c('1986-10-01', '1994-10-25', '2011-03-01', '2013-10-01')) , color = 'blue') + 
  # annotate('segment', x = date_beg_model, xend = date_end_model, y = 3500, yend = 3500 ) +
  ylab( paste0('Stage, in feet above ', site_info$alt_va, ' ', site_info$alt_datum_cd,
  '                           Flow, in cubic feet per second') )  +
  ggtitle( paste0('Figure ', fig_no, '. Discrete flow measurements at 04122500 Pere Marquette River at Scottville, \n Mich. during the period with accessible discrete measurement data.') )


```

***  

#### Types of Controls and Accuracy Qualifiers  

Discrete flow measurement data for Pere Marquette River occurring during the period of analysis were retrieved from the USGS National Water Information System (NWIS) using the R package dataRetrieval [@DeCicco2019]. Table `r tab_no + 1` summarizes the type of control and the accuracy of discrete flow measurements provided by the qualifier. The most common control conditions were a 'Clear Channel', and the most common measurement accuracy qualifier was 'Good.'  

Two discrete measurements were removed from the analysis because they were considered to be outliers with respect to persistent changes in the stage-flow relation. Measurement number 474, obtained on Jan. 28, 1986, and measurement number 657 measured Dec. 11, 2013, were removed. Both measurement indicated the control type as 'Shore Ice,' but were indicating backwater departures from the rating relation more consistent with 'Ice Covered' measurements. The two measurements were qualified as 'fair', and 'poor,' respectively.  

The qualifiers assigned to discrete flow measurements by hydrographers in the field were used to estimate uncertainties of the measured flows.  In this paper, a qualifier of 'Excellent' was associated with a standard error of 2 percent; 'Good,' with a standard error of 5 percent; 'Fair,' with a standard error of 8 percent; and 'Poor,' with a standard error of 12-percent. The associations are loosely based on the 'Discharge Measurement Quality Code' descriptions by USGS NWIS at https://help.waterdata.usgs.gov/codes-and-parameters/discharge-measurement-quality-code, accessed Jan. 18, 2020.   
  
```{r measurement_type_freq, echo = FALSE, message = FALSE}

# Increment table counter
tab_no <- tab_no + 1
table( discrete_meas$control_type, discrete_meas$qualifier ) %>%
  rbind(c(sum(discrete_meas$qualifier == 'Excellent'),
          sum(discrete_meas$qualifier == 'Good'),
          sum(discrete_meas$qualifier == 'Fair'), 
          sum(discrete_meas$qualifier == 'Poor'))) %>% 
  cbind(c(sum(discrete_meas$control_type == 'Clear Channel'),
          sum(discrete_meas$control_type == 'Light Vegetation'),
          sum(discrete_meas$control_type == 'Light Debris'),
          sum(discrete_meas$control_type == 'Shore Ice'),
          sum(discrete_meas$control_type == 'Moderate Debris'),
          sum(discrete_meas$control_type == 'Ice Cover'),
          nrow(discrete_meas))) %>% 
  kable( digits = 4, 
         caption = paste0('Table ', tab_no, '. Frequency of flow measurements by stream channel control type and flow measurement qualifiers at ',
         site_info$site_no, ' ', site_info$station_nm, 'from ', date_beg_model, ' to ', date_end_model),
         col.names = c( 'Excellent', 'Good', 'Fair', 'Poor', 'Total') ) %>%
  kable_styling() %>% 
  add_header_above(c("Type of Control" = 1, "Discrete Flow Measurement Qualifier" = 4, ' '), align = 'center') %>% 
  footnote('Discrete measurements with the type of control "Ice Cover" were subsequently deleted from the analysis because they did not reflect persistent changes in the stage-flow relation. Also, "check" measurements, which are repeated flow measurements on the same day to confirm the accuracy of the initially measured flow, were made on two days during the period of analysis. An average flow was computed from the two measurements to represent the discrete flow on that day.')

# Remove ice cover measurements
discrete_meas <- discrete_meas %>% 
  dplyr::filter( control_type != 'Ice Cover' ) 
  # dplyr::select( 'measurement_nu', 'measurement_dt',
  #                'stage_discrete_mea', 'flow_discrete_mea', 'qualifier',  'control_type',
  #                'se_pct', 'se_flow' )


# Assign first 471 - 478 discrete measurements to rating 17
ndx_rat <- which(discrete_meas$measurement_nu < 479)
discrete_meas$rating_no[ ndx_rat ] <- 17
# Add measurements 479 and 480 to the set used for 18 because of the highest
ndx_rat <- which(discrete_meas$measurement_nu > 478 & discrete_meas$measurement_nu < 481)
discrete_meas$rating_no[ ndx_rat ] <- 18

# Compute time between consequtive flow measurements
df <- data.frame( Date = discrete_meas$Date[1:(nrow(discrete_meas)-2)],
                  'days_between_measurements' = diff(discrete_meas$Date, 1)[1:(nrow(discrete_meas)-2)])



```

***

#### Time Between Discrete Flow Measurements  

The frequency of discrete flow measurements is an important factor in detecting persistent and intermittent changes in the stage-flow rating, and in determining the costs of field operations.  During the period of analysis at Pere Marquette River, the mode of the distribution of time between discrete measurements was 42 (fig `r fig_no + 1`). There is some evidence from the plot that the time between discrete measurements increased after 1993. There are no extended gaps in discrete flow measurements.  The two measurements at zero time between measurements are from check measurements made to ensure the initially measured flow.   


```{r days_between_meas, messages = FALSE, warning = FALSE } 

# Increment figure counter
fig_no <- fig_no + 1

p <- df %>% 
  ggplot( aes( x = Date, y = days_between_measurements)) +
  geom_point( ) +
  theme_bw() +
  xlab( 'Date' ) +
  ylab( 'Time between flow measurements, in days' ) +
  ggtitle(paste('Figure', fig_no, '. Distribution of days between consecutive flow measurements at \n streamgage 04122500 Pere River at Scottville, MI'),
          subtitle = 'Bin widths include 5 days.') +
  annotate('segment', x = as.Date('1985-01-01'), xend = as.Date('2020-01-01'),
                      y = 43.5,                  yend = 43.5, 
           color = 'blue', linetype = 'dashed') +
  annotate('text', x = as.Date('1986-01-01'), y = 50, label = 'Mode: 42', color = 'blue') 

  suppressMessages( ggExtra::ggMarginal(p, type = "histogram", margins = 'y') )
  # geom_rug( size = 0.05, sides = 'r' )

```

***

### Continuous Stage Data  

Stage is generally measured continually at streamgages using float sensors, bubble-gages, or pressure transducers [@rantz1982] to indicate water-surface elevations.  Elevations are commonly measured directly in feet above a gage datum, in which zero is some distance below the water-surface elevation at which zero streamflow occurs.  The zero of the gage datum is also referenced to a standard vertical datum.  For 04122500 Pere Marquette River at Scottville, Mich. the gage datum  is North American Vertical Datum of 1929 (NAVD29).  

Unit and daily stage data were considered primarily as instrumental variables in the computation of unit and daily flows. Thus, the accessibility of historical unit and daily stage data is more limited than daily flow data. In particular, limitations in the availability of historical stage data constrained the start of the period of analysis utilized in this paper.  


#### Frequencies of Unit Stage Data  

The number of unit values recorded per day varied during the period of analysis (fig. `r fig_no + 1`). From about October 1, 1989 to May 4, 1994, 24 values per day was common; from May 5, 1994 to February 21, 1997, 288 values per day (5-minute interval data) were common; and after February 21, 1997, 96 values per day (15-minute interval data) were common. Other small irregularities associated with missing unit values occurred during the period of analysis at all measurement frequencies.  

In developing this approach, a simple method was used to adapt to changing frequencies or absent of unit (or daily) stage data. For periods when unit stage data was available, a daily mean value was computed from all unit stage data for that day. On days when no unit (or daily) stage data was available, the published daily mean flow was used with an inverse application of the stage-flow rating to estimate a daily mean stage. This allowed model computations at daily time steps rather than (possibly variable) unit time steps substantially increasing the speed of parameter estimation in the model.   


```{r unit_daily_stage, warning = FALSE }

if( file.exists('stage_unit.RData')){
  # print('Loading published unit stage data from RData file.')
  load('stage_unit.RData')
} else {
  print('Retrieving daily flow from Aquarius Retrieval')
  stage_unit <- read.csv('Data/04122500/stage/Gage_height.ft@04122500.EntireRecorda.csv', 
                         header = TRUE, sep = ',', stringsAsFactors = FALSE, comment = '#')
  # Standardize field names
  stage_unit     <- renameNWISColumns(stage_unit)
  stage_unit$dateTime <- as_datetime(stage_unit$Timestamp..UTC.05.00, tz = 'America/New_York')
  colnames(stage_unit)[3] <- 'stage'
  save(stage_unit, file = 'stage_unit.RData')
}

# Summarize unit stage to daily mean stage
stage_day <- stage_unit %>% 
  group_by(day = floor_date( dateTime, 'day')) %>% 
  summarize( stage_daily_mean  = mean( stage, na.rm = TRUE ),
             n         = n()) 

fig_no <- fig_no + 1
suppressMessages(stage_day %>% 
  # Remove row with missing values
  ggplot( aes( x = as.Date(day), y = n)) +
  geom_point( color = 'black', alpha = 0.5, shape = 16, size = 1 ) +
  geom_vline( xintercept = as.Date( c('1994-05-04', '1997-02-21'), format('%Y-%m-%d')), 
              linetype = 'dotted', color = 'black' ) +
  theme_bw() +
  xlab('Date') +
  ylab('Number of unit values per day') +
  ggtitle( paste0('Figure ', fig_no, '. Number of unit stage values per day at 04122500 Pere Marquette River \\ at Scottville, Mich. during the period of analysis' )))

stage_day <- stage_day %>% 
  ungroup() %>% 
  arrange( day ) %>% 
  mutate( delta_day = as.numeric(day - lag( day ), units = 'days' ),
          day_date  = as.Date( day )) 

```
` 

```{r }

# Measured flows and daily stages for the interval when rating 19 was active
#  Note: Discrete measurement timing is approximated to days

df_stage_flow_allDays <- data.frame(day = seq.Date(from = date_beg_model, to = date_end_model, by = '1 day'))

# calculate_mode function from https://exploratory.io/note/kanaugust/1701090969905358
#   Used in subsequent summarize
calculate_mode <- function(x) {
  uniqx <- unique(na.omit(x))
  uniqx[which.max(tabulate(match(x, uniqx)))]
}

# Take the mean flow and stage for days of multiple flow measurements
df_discrete_meas <- discrete_meas %>% 
  group_by( Date ) %>% 
  summarize( flow_discrete_mea       = mean( flow_discrete_mea ) ,
             stage_discrete_mea      = mean( stage_discrete_mea     ) ,
             n                       = n(),
             qualifier               = calculate_mode(qualifier),
             control_type            = calculate_mode(control_type),
             se_pct                  = mean(se_pct),
             se_flow                 = mean(se_flow))

# Integrate daily flow and discrete measurements 
df_stage_flow_allDays <-df_stage_flow_allDays %>% 
  left_join( df_discrete_meas[, c('Date', 'flow_discrete_mea', 'stage_discrete_mea',
                                  'qualifier', 'control_type', 'se_pct', 'se_flow')], 
             by = c( 'day'  = 'Date')) %>% 
  left_join( stage_day[, c('day_date', 'stage_daily_mean')], by = c( 'day' = 'day_date' )) %>% 
  filter( day >= date_beg_model & day <= date_end_model )


```



```{r read_ratings, results = 'hide' }

# Rating curve at the selected site.  The 'exsa' parameter is an extended table
#   provide detailed info on stage discharge

rating18 <- read.csv('Data/04122500/04122500_rating_18.0.txt', header = FALSE, sep = '\t') 
colnames( rating18 ) <- c('rated_flow', 'stage')

# Use rating18 as the initial rating
rating_init   <- rating18
#   Rename column rated18_flow to rated_flow_init
colnames(rating_init)[1] <- 'rated_flow_init'

rating19 <- read.csv('Data/04122500/04122500_rating_19.0.txt', header = FALSE, sep = '\t') 
colnames( rating19 ) <- c('rated_flow', 'stage')

rating20 <- read.csv('Data/04122500/04122500_rating_20.0.txt', header = FALSE, sep = '\t') 
colnames( rating20 ) <- c('rated_flow', 'stage')

rating21 <- read.csv('Data/04122500/04122500_rating_21.0.txt', header = FALSE, sep = '\t') 
colnames( rating21 ) <- c('rated_flow', 'stage')


suppressMessages(rating_wide <- rating18   %>%  
  full_join(   rating19 ) %>% 
  full_join(   rating20 ) %>% 
  full_join(   rating21 ) %>% 
  dplyr::select(stage, everything() ))
  
rating_long <- rbind(rating18, rbind(rating19, rbind(rating20, rating21)))
rating_long$rating_no <- c(rep(18, nrow(rating18)), rep(19, nrow(rating19)), 
                           rep(20, nrow(rating20)), rep(21, nrow(rating21)))

```

#### Estimation of missing stage values

A stage-flow relation is adapted by changing GAM parameters on the basis of discrete measurements of stage and flow.  Intervening measurements of stage, however, can be used to generate a set of basis functions (one for each knot) from an underlying GAM and used to compute the magnitudes and uncertainties of daily or unit streamflow. 

The time series of computed daily mean stage values (fig. `r fig_no + 1`) shows a seasonal variation within which annual minimums appear to have a downward trend. In particular, during the early 1990s, minimum annual stage values were generally greater than 1.6 ft above gage datum, while during the 2010s, minimum annual stage values were generally 0.6 ft lower. This pattern is consistent with the possible trend in the discrete measurements of stage data discussed earlier. The datum of the gage is 597.66 ft above National Geodetic Vertical Datum of 1929 (NGVD29). Based on visual inspection of the time series, the variability of stage values may be increasing with time.

Most of the missing daily mean stage values occurred during the period Rating 18 was in effect (fig. `r fig_no + 1`). Thus, daily mean flows were used with Rating 18 flow-stage relation to estimate all missing daily mean stage values. 


```{r missing_stage, warning = FALSE, fig.width = 8 }

df_stage_flow_allDays <- df_stage_flow_allDays %>% 
  left_join( flow_daily_pub[, c('Date', 'Flow')], by = c('day' = 'Date')) %>% 
  rename( 'flow_daily_pub'    = 'Flow',
          'Date'              = 'day')


# find indices of missing stage_mean_day values
ndx_ina <- which( is.na(df_stage_flow_allDays$stage_daily_mean ))

# find indices of bad daily stage from bad unit stage (1994-09-13 to 1994-09-19)
ndx_bad <- which( df_stage_flow_allDays$Date >= as.Date('1994-09-13') & 
                  df_stage_flow_allDays$Date <= as.Date('1994-09-19'))

ndx_miss <- sort(c(ndx_ina, ndx_bad))

# Find dates for missing data
dates_missing <- df_stage_flow_allDays$Date[ndx_miss]

# Estimate daily mean stage from published daily mean flow using rating 18, which was active when most of the missing values occurred)
stage_missing <- approx( x = rating18$rated_flow, y = rating18$stage, 
                         xout =df_stage_flow_allDays$flow_daily_pub[ndx_miss])

# Estimated missing daily stage on the basis of published daily mean flow 
df_stage_flow_allDays$stage_daily_mean[ ndx_miss ] <- stage_missing$y
df_stage_flow_allDays$stage_data               <- 'Measured'
df_stage_flow_allDays$stage_data[ ndx_miss ]   <- 'Estimated'

df_stage_flow_allDays <- addWaterYear(df_stage_flow_allDays)

min_Stage_group_waterYear <- df_stage_flow_allDays %>% 
  dplyr::group_by( waterYear ) %>% 
  summarize(minStage = min(stage_daily_mean),
            minDate  = Date[ which.min(stage_daily_mean) ])


fig_no <- fig_no + 1
df_stage_flow_allDays[, ] %>% 
  ggplot( aes( x = Date, y = stage_daily_mean, color = stage_data )) +
  geom_point( size = 1 ) +
  geom_vline( xintercept = as.Date( c('1994-10-25', '2011-03-01', '2013-10-01')) , color = 'blue') + 
  # geom_line( data = min_Stage_group_waterYear, aes( x = minDate, y = minStage ), color = 'red') +
  theme_bw() +
  xlab('Date') +
  theme( legend.position = 'bottom') +
  scale_y_sqrt( breaks = c(1,2,4,6), limits = c(1,7)) +
  annotate('text', x = as.Date('1990-01-01'), y = 7, label = 'Rating 18', hjust = 'left') +
  annotate('text', x = as.Date('2003-01-01'), y = 7, label = 'Rating 19', hjust = 'left') +
  annotate('text', x = as.Date('2012-01-01'), y = 7, label = '20',        hjust = 'left') +
  annotate('text', x = as.Date('2016-01-01'), y = 7, label = 'Rating 21', hjust = 'left') +
  ylab('Stage, in feet above gage datum of 597.66 ft NAVD29') +
  ggtitle( paste0('Figure ', fig_no, '. Time Series of daily mean stage computed from unit values at \n04122500 Pere Marquette River at Scottville, Mich., during the period of analysis'),
           subtitle = paste0('Vertical blue lines indicate ', length(ndx_miss), ' days of missing stage that were estimated.'))
  
```


***

### Stage values used in modeling

Figure `r fig_no + 1 ` shows the close correspondence  between discrete stage on days of field measurements and daily mean stage computed from unit values.  Only one estimated stage occurred on a day of a discrete measurement. For the purpose of modeling flows and tracking the changes in the stage-flow relation, daily mean stages were replace with measured discrete stages on days of field measurement so that even the small discrepancy between discrete stage measurements and daily mean stage did not degrade modeling accuracy.  



```{r mean_discrete stge}

# 
# Substitute discrete stage and time of discrete flow measurement
#   Find indices of discrete stage-flow measurements
ndx_ian <- which( !is.na( df_stage_flow_allDays$stage_discrete_mea ) )


fig_no <- fig_no + 1
df_stage_flow_allDays[ ndx_ian, ] %>% 
  mutate( stage_data = factor( stage_data, levels = c('Measured', 'Estimated'))) %>% 
  ggplot( aes( x = stage_discrete_mea, y = stage_daily_mean ) ) +
  geom_point( aes( color = stage_data, shape = stage_data ), alpha = 1 ) +
  theme_bw() +
  scale_x_log10( breaks = seq(1, 6, by = 1) ) +
  scale_y_log10( breaks = seq(1, 6, by = 1) ) +
  geom_abline( intercept = 0, slope = 1, color = 'salmon') +
  xlab('Stage at time of discrete flow measurements, in feet above streamgage datum') +
  ylab('Daily mean stage on days of discrete measurements, in feet') +
  ggtitle(paste0('Figure ', fig_no, '. Relation between discrete stage and daily mean stage \non days of discrete flow measurements.'))


#   Find discrepancies between daily mean and discrete stage on days of discrete measurements
del_stage <- df_stage_flow_allDays$stage_discrete[ ndx_ian ] - df_stage_flow_allDays[ ndx_ian, 'stage_daily_mean' ]
#   Find index of largest (positive) discrepancy
ndx_day <- which( del_stage == max( del_stage) )

# Find indices of unit stage on day of max stage discrepancy 
ndx_unit_stage <- which( as.Date(stage_unit$dateTime) == df_stage_flow_allDays$Date[ ndx_ian][ndx_day] )
# Result is an empty vector.  There are no unit stages on this day.
ndx_stage <- which( as.Date(stage_unit$dateTime) == as.Date('1992-07-22') ) 



```





***

### Selected Stage-Flow Ratings 

Stage-flow ratings 18-21 were retrieved from USGS NWIS data bases using Aquarius Time-Series Software [@Aquarius2017]. The expanded form of the ratings 18-21 were exported in column format. The expanded rating indicate the relation between stage and flow at 0.01 ft increments of gage height. Table `r tab_no + 1` showing the starting and ending dates for each of the selected ratings and the number of discharge measurements in the corresponding interval when the ratings were applied. 


```{r rating_history, fig.width = 5 }

# Read rating history
rating_history <- read.csv( 'Data/04122500/rating_period_start_end.txt', sep = '\t', header = TRUE,
                            colClasses = c('numeric', 'Date', 'Date'), comment.char = '#')

# Increment table counter
tab_no <- tab_no + 1

# Print table showing the number of discrete measurements by rating period
suppressMessages(tmp <- discrete_meas %>% 
  # rename( 'rating_no' = 'effective_rating') %>% 
  group_by( rating_no ) %>% 
  summarize( no_meas = n()) %>% 
  left_join( rating_history ) %>% 
  dplyr::select(rating_no, start_date, end_date, no_meas) %>% 
  filter( rating_no >= 18))

tmp %>% 
  dplyr::filter( !is.na( rating_no )) %>% 
  kable( caption = paste0('Table ', tab_no, '. Number of discrete flow measurements during selected rating periods at streamgage 04122500 Pere Marquette River at Scottville, Mich. during the period of analysis '),
         col.names = c('Rating number', 'Starting date', 'Ending date', 'Number of \n discrete \n measurements')) %>% 
  kable_styling( full_width = F, position = 'left') %>% 
  column_spec(1, width = '6em' ) %>% 
  column_spec(2, width = '6em' ) %>% 
  column_spec(3, width = '6em' ) %>% 
  column_spec(4, width = '3em' ) %>% 
  add_header_above( c('Rating Period' = 3, ' ') ) 
  # footnote('Discrete measurements that were obtained during the rating period were included in the number of count of discrete measurements for that rating. Discrete measurement 479 and 480, which occurred on Sept. 13, 1986, and Sept. 17, 1986, were included in rating period 18 because they were associated with the maximum stage measured at the streamgage.')




```

***

#### Plot of selected stage-flow ratings with corresponding discrete measurements


Figure `r fig_no + 1` shows historical rating curves 18-21 and corresponding discrete flow measurements during the selected rating periods.  A persistent shift to the right is evident in the plot indicating higher rates of flow are discharged at the same stage as time increases. The historical rating curves that were developed manually track these changes closely. Ratings 18 and 21 are generally parallel and provide the left and right boundaries for rated flows during the selected period of analysis, while ratings 18 and 19 are more irregular. Specifically, ratings 19 and 20 are well separated at flows less than 2,800 ft^3^/s, but converge at greater flows. The two essentially identical ratings then and converge with rating 18 at the 6,500 ft^3^/s and 8.1 ft of stage.  Ratings 20 and 21 are nearly overlapping at flows less than 2,000 ft^3^/s. Rating 21 shows a sharp decrease in slope at about 1,700 ft^3^/s, and crosses rating 20. Rating 21 continues to 7,300 ft^3^/s at 8.1 ft of stage, perhaps to account for the highest measured flow of about 4,850 ft^3^/s during the period of analysis. At 8.1 ft of stage, rating 18, 19, and 20 indicate a flow of 6,500 ft^3^/s, while rating 21 indicates a flow of 7,300 ft^3^/s, or about 12.3 percent more flow than ratings 18-20. 


```{r plot_ratings_meas, fig.width = 9, fig.height = 8,}

# Increment fig_no
fig_no <- fig_no + 1

rating_long %>% 
  ggplot( aes( x = rated_flow, y = stage,  color = rating_no)) +
  geom_line( aes( color = factor(rating_no) ), size = 1.0, alpha = 0.50) +
  theme_bw() +
  geom_point( data = discrete_meas[ 9:nrow(discrete_meas), ], aes( x = flow_discrete_mea, y = stage_discrete_mea, 
                                         color = as.factor(rating_no))) +
  # geom_text(data = discrete_meas, aes( x = Date, y = stage_discrete_mea, label = measurement_nu ), hjust=0, vjust=0) +
  # facet_wrap( ~ rating_no) +
  theme( legend.position = 'bottom' ) +
  scale_x_continuous( breaks = seq(1000, 7000, by = 1000)) +
  scale_y_continuous( breaks = seq(   1,    8, by =    1)) +
  xlab( 'Flow, in cubic feet per second' ) +
  ylab( 'Stage, in feet above gage datum' ) +
  annotate('text', x = c(1300, 1950, 3200, 5200), y = c( 4.0, 4.7, 6.0, 7.0), 
           label = c('18', '19', '20', '21')) +
  labs( title =  paste0('Figure ', fig_no, '. Discrete flow measurements for selected rating curves at ', site_info$site_no, '\n', site_info$station_nm ) )

  
```

## Methods for Adapting Stage-Flow Rating to Sequential Discrete Flow Measurements

Using a generalized additive modelling framework[@Wood2006], a cubic regression spline (CRS) is used to approximate either an existing rating or develop a new rating from a set of discrete stage-flow measurements.  Parameters of the CRS form the state vector of a state-space model, which is composed of a state equation and a measurement equation. In this analysis, the state-space model is computed at daily time steps.  

The uncertainty of the state vector increases with time between measurements based on an estimated process variance matrix $Q$ within the state equation. The state vector is premultiplied by a set of basis functions with compatible length (computed as a function of stage), to estimate measured flow. On days when a discrete measurement occurs, the parameters in the state vector are updated to adapt the rating curve to reduce the differences between the estimated and measured flows, and to reduce the uncertainty described by the state covariance matrix $V$.  

The remaining discrepancies between discrete measurements of flow and estimated flow, both in natural logarithmic units, are described by the measurement variance $R$ in the measurement equation. The value of $R$ can be specified or estimated iteratively. Once, $Q$ and $R$ are obtained, a set of CRS parameters can be obtained that sequentially adapt the rating curve based on each discrete flow measurement used in the analysis. In addition, a Kalman filter [@Simon2006] can be applied to estimate the magnitude and uncertainty of daily or unit flows based on daily or unit stages. Details of this process are described in the following paragraphs. 

### Cubic Regression Splines

Cubic regression splines (CRSs) are piecewise polynomials with constraints to ensure continuity to the second derivative at interior knots and zero second derivatives at the boundary knots [@Wood2006].  Individual polynomials are third order. Special constraints on the boundary knots ensures linear extrapolation beyond the domain of the stage data. CRS parameters were estimated within a generalized additive model (GAM) to flexibly represent the monotonically increasing relation between stage and flow. The GAM package 'mgcv' [@mgcv2019] provided parameter estimation, statistics on model fit, and utility functions like matrix.model() and predict() for developing the CRSs within the R [@cite_R] programming environment. 

A linear form of the CRS was used by specifying a set of basis functions such that $b_j(x)$ is the $j^{th}$ function of the set.  A simple third-order (cubic) polynomial basis can be represented with basis functions $b_0(x) = 1$, $b_1(x) = x$, $b_2(x) = x^2$, and $b_3 = x^3$, so that $y_i = \beta_0 + x_i \beta_1 + x_i^2 \beta_2 + x_i^3 \beta_3 + e_i.$ Thus, a third order polynomial has four basis functions ${1, \ x, \ x^2, \ x^3}$ and four corresponding parameters ${\beta_0, \ \beta_1, \ \beta_2, \ \beta_3}$.  According to [@Wood2017], a polynomial basis is a useful approximation for a specific point, however, splines are preferred when interest in the response of flow is over the entire domain of stage. 

CRSs used in this analysis were specified as having 5 knots, which was thought to be sufficiently flexible for the stage-flow relations at the selected streamgage. Five knots resulted in two boundary knots at the minimum and maximum of the stage data, and three interior knots at the 25^th^-, 50^th^-, and 75^th^-percentiles. More generally, the *gam* function defaults to placing the interior knots at even quantiles of the data, but can be replaced with manual specification more consistent with apparent breaks in the curvature of the rating. The basis functions themselves are not affected by the response variable (flow).  

The linear form of the basis functions used in the analysis can be written as:  

$$ flow(stage_i) = {\displaystyle \sum_{n=0}^{4} b_j(stage_i) \space \beta_j + \varepsilon_i} $$

#### Specification of a Cubic Regression Spline within a Generalized Additive Modelling Framework

Within the R package *mgcv*, the **gam** function produces a gam output object (gamObject) that contains the parameters, statistics, and input data of a gam model. The syntax below shows the arguments to the gam function, which describe the model structure, and provide data for estimation of model parameters and summary statistics.   

gamObject <- gam( flow        ~ s(stage,             bs = 'cr', k = knts),  
                       data = data.frame( stage = ..., flow = ... ), family = Gamma(link = log))  


| Model Syntax            |  Explanation                                                                                              |  
|:------------------------|:----------------------------------------------------------------------------------------------------------|  
|: gamObject         |: The gam object produced as model output                                                                  |  
|: gam( ... )         |: Function from the R package 'mgcv' used to specify the gam model                                         |     
|:  ~                 |: Relational operator                                                                                      |  
|: s( ... )           |: Function 's' is used to specify spline terms within gam model formula [@mgcv2019]. |  
|: bs = 'cr'        |: bs is an input argument that accepts a code for the type of smoothing bases. The 'cr' indicates a CRS  |  
|:                        |:    Cubic Regression Spline [@mgcv2019]                                                                         |  
|: k = knts         |: k is an input argument for the number of knots, which is specified in this analysis as 5. The preferred number of knots may vary among streamgages. |    
|: data = [rating | discrete pairs  |: The dataframe used in the analysis, with partial listing below this table                                |  
|: family = Gamma(link = log) |: A family is a parametric set of probability distributions of a certain form. In this case, the gamma distribution, which is a member of the exponential family, may be appropriate because the distribution of the natural logarithms of daily mean flows is consistent with the gamma distribution. |


```{r echo = FALSE, eval = FALSE }
print('First 6 rows of data in data.frame rating18')
print( head( rating18 ))
```

Once the gam model is estimated, the spline parameters (coefficients) and basis functions can be extracted from the gamObject. The spline parameters can be extracted using the function *coefficients* as coefficients( gamObject ). Two ways to extract the basis functions that form the design matrix $Z$ are presented. The *model.matrix* function can be used to extract the basis functions used in model development as $Z = $ model.matrix( gamObject ). In this case, a (design) matrix is returned with the number of rows equal to the number of observations in the data set used to estimate the gam model. The number of columns returned equals the number of knots in the spline.  The first column in the design matrix is a column of ones corresponding to the intercept. Alternatively, a design matrix can be obtained by use of the *predict* function, using the arguments $Z = $ predict( gamObject, newdata = data.frame( stage = ..., flow = ...), type = 'lpmatrix'  ). The *predict* function is a convenient way to generate basis functions for time series of unit or daily stage data used in computation of streamflow records, where *newdata* takes on time series  of stage (and flow) values. 

### State-Space Model

A state-space model consists of two equations: a state equation, and a measurement equation. The left-hand-side state vector of length *n* equal to the number of knots, $\vec{x}_{t}$ contains unobservable states, which here correspond to the five parameters of the CRS at time *t.*  The states are updated from observations in the measurement vector (scalar in this case) $\vec{y}_{t}$. These updates are based on the Kalman gain, computed using variance of the state vector, $V$ and the variance of the flow measurement $R$ [@marss2018]. The state and measurement equations are solved alternately for each time step indexed by $t.$ The state-space model is written below:


$$
\begin{align}
\text{ State Equation:  } \vec{x}_{t}  &= \: \vec{x}_{t-1} +  \vec{w}_{t} && \text{where } \vec{w}_{t} \text{~} MVN(0, Q) \text{,}\\
 \text{Measurement Equation:  } y_{t} &=     \vec{Z}_{t}{'} \text{ } \vec{x}_{t} + v_t && \text{where } v_t \text{~} N(0, R_{t}) \text{,}\\
 \text{}
\end{align}
$$
where $MVN(\vec0,Q)$ indicates a *Multi-Variate Normal* vector with mean $\vec{0}_{n}$, and process covariance $Q$.  
Similarly, $N(0, R_{t})$ indicates a *Normally* distributed error with mean $0$ and scalar or time series measurement variance $R$ or $R_t$.  

#### State Vector $\vec{x}_t$

Vector $\vec{x}_t$ is the time series of state vectors, where each vector has a length of corresponding to the number of knots specified for the CRS. The state equation forecasts the transition of the state vector from time $t-1$ to $t$ as a random walk. The state-vector is updated only at times (on days) of discrete flow measurements. If the measurement vector contains a missing value indicator, the measurement update is skipped and the state vector is unchanged. The covariance of the state vector before the measurement update $V_t^-$, however, is incremented by $Q$ at each time step in the state equation, while  $V_t^+$ is state variance updated (reduced) only when discrete flow measurements are indicated in the $y_t$ vector. 


#### Measurement Time Series $y_t$

The scalar measurement time series $y_t$ has a length equal to the number of days in the period of analysis. Although the series represents flow at daily increments of time, $y_t$ contains the natural logarithms of discrete flows, in cubic feet per second, on days of field measurements. The natural logarithm transformation makes the parameterization of the state-space model consistent with the associated GAM model. The natural logarithm is used in $y_t$ to help ensure that the measurement errors $v_t \sim N(0, R)$ and that (small) variances of flow measurements, which are based on percentages of measured flows, are compatible flows modeled in natural logarithm units. On days when no flow measurement occurred, the elements in the vector contain an *NA* value, so that no measurement update occurs to the state vector, although the state covariance matrix increases because of the increase in forecast uncertainty. In this analysis, $y_t$ vector was composed of mostly (98.3 percent) *NA* indicators. 

#### Process Covariance Matrix $Q$

The random process noise vector $\vec{w}_t$ is assumed to have a multivariate-normal distribution (MVN) with mean $\vec{0}$ and fixed covariance $Q$.  The process covariance matrix $Q$ increases the uncertainty of the state vector $\vec{x}_t$, which is characterized in the time-varying state covariance matrix $V_t$ [@simon2006].  

The process covariance reflects the increase in uncertainty with the forecast from time $t-1$ to time $t$. According to [@MARSS2018], the maximum likelihood estimates of $Q$ and $R$ are biased, and this bias is more severe when either $Q$ or $R$ are small. This bias arises because variance is constrained to be positive, and this variance does not go to zero with increasing sample size. So that $Q$ was as large as practical while accurately identifying the timing of discrete measurements to the day, a daily time step was used for the estimation of $Q$. This discretization is thought to be adequate for describing the uncertainty of parameters of the rating curve. When estimating the uncertainty of unit flow magnitudes, however, linearity would be applied so that the daily $Q$ value would be divided by the number of unit time steps per day to better approximate the increase in variance of flow at unit time intervals.  

The state equation update represents a forecast to the next time step, and the state covariance matrix reflects this uncertainty by increases in covariance matrix after the forecast $V_{t-1}^{+}$, but before the measurement update $V_{t}^{-}$. If there is a discrete flow measurement at time $t$, the state covariance matrix is decreased by the information in the measurement to $V_{t}^+$. Otherwise, there is no reduction in the state covariance, which continues to increase as a function of $Q$ until a discrete flow measurement occurs. The initial state covariance matrix can be initialized at time zero, $V_0^+$.  Generally, the initial value is set sufficiently large so that the state vector is appropriately sensitive to information in discrete measurements after time zero. More frequent discrete measurements decrease the state covariance matrix and increase the rate at which the rating relation can adapt to persistent changes.  A reduction in the state covariance matrix also reduces the uncertainty of the streamflow record. 

Daily time steps were used in this paper because the most frequent time between discrete flow measurements was 42 days. On average, therefore, there is one measurement update for each 42 state updates in the alternating solution of the state space model. Estimating state-space model parameters at unit intervals would increase the computational burden of solving the state equation by one or two orders of magnitude using hour or 15-minute time steps were used. In addition, the estimation results may be degraded. In particular, [@marss2018] note that when $Q$ (or $R$) gets very small, the bias in the maximum-likelihood estimates of variances becomes more severe. The magnitude of $Q$ is generally small ($<10^{-05}$) even at daily time steps. Alternatively, one might estimate $Q$ at daily time steps and divide $Q$ by the number of time steps in a day for simulation. 

equation, and the reduction in variance in measurement equation $V_t^+$. If the process variance is estimated by use of daily time steps, the resulting variance reflects the day to day increase in the uncertainty of the CRS parameters. If subsequently, the simulation time increment were to change to 15-minute intervals, for example, the daily process variance divided by 96 is suggested as a suitable estimate of the unit process variance. In this analysis, $Q$ is unknown, but estimated as diagonal matrix in various forms. 

In this paper, the process variance Q is a $5\times5$ matrix, corresponding to the dimension of the state vector. The state vector represents the 5 parameters in the initiating GAM model, which is specified by the number of knots in the CRS. The covariance matrices took on four general forms that can be defined by special tags defined within the MARSS software [@marss2018]. These tags include 'diagonal and equal', 'diagonal and unequal', 'equalvarcov', 'unconstrained,' in which the tag provides a shortcut string to define a particular form of the matrix. For example, in the model specification, the process covariance matrix can be explicitly defined as: 'Q = 'diagonal and equal' or explicitly as 'Q =  A custom form of Q is referred to in this paper as the 'std diagonal multiplier' form for standardized diagonal multiplier, but this nomenclature is not meaningful within the MARSS software. The diagonal forms are based on the assumption that changes in parameter values are independent. Estimation of off-diagonal terms, however, may be more consistent with covariance effects among parameters, and some of these forms are estimated and evaluated. The forms of these matrices are illustrated and discussed below. 

##### Forms of Q

*Diagonal and Equal Form of Q*

The Q matrix can be defined by the MARSS-specific tag 'diagonal and equal' as Q = 'diagonal and equal'. Alternatively, this matrix can be defined using the more general R syntax as: Q = matrix(list('q',0,0,0, 0, 0,'q', 0, 0, 0, 0, 0, 'q', 0, 0, 0, 0, 0, 'q', 0, 0, 0, 0, 0, 'q'), 5, 5). The two definitions produce identical results within the MARSS framework. The specification indicates that all diagonal terms in the covariance matrix take on the same unknown value, and that all off-diagonal terms all equal zero.  This single parameter is estimated within the MARSS software. 

$$ Q_1 (diagonal \ and \ equal) =  \begin{bmatrix} q & 0 & 0 & 0 & 0 \\ 0 & q & 0 & 0 & 0 \\ 0 & 0 & q & 0 & 0 \\ 0 & 0 & 0 & q & 0 \\ 0 & 0 & 0 & 0 & q\\ \end{bmatrix}$$
*Diagonal and Unequal Variances Form of Q*

The designation Q = 'diagonal and unequal' implies that five unique parameters on the diagonal are estimated $(q_{11}, q_{22}, \dots,q_{55})$ are estimated, and that all off-diagonal terms equal zero.  

$$ Q_2 (diagonal \ and \ unequal) =  \begin{bmatrix} q_1 & 0 & 0 & 0 & 0 \\ 0 & q_2 & 0 & 0 & 0 \\ 0 & 0 & q_3 & 0 & 0 \\ 0 & 0 & 0 & q_4 & 0 \\ 0 & 0 & 0 & 0 & q_5\\ \end{bmatrix}$$
*Equal Variances and Covariances Form of Q*

The designation Q = 'equalvarcov' implies that all process variances along the diagonal take on a common value, and that all off-diagonal terms describing covariance take on a common value. Thus, the 'equalvarcov' matrix only has two estimated parameters. 

$$ Q_3 (equalvarcov) =  \begin{bmatrix} q & c & c & c & c \\ c & q & c & c & c \\ c & c & q & c & c \\ c & c & c & q & c \\ c & c & c & c & q\\ \end{bmatrix}$$

*Unconstrained Form of Q*

The Q = 'unconstrained' case for a covariance matrix is actually constrained to be a symmetrical and positive definite matrix, which guarantees invertibility. So, this $5 \times 5$ Q matrix has only 15 unique elements that are estimated rather than 25. The 'unconstrained' form attempts to describe covariance among all parameters.

$$ Q_4 (unconstrained) \ =  \begin{bmatrix} q_{11} & q_{21} & q_{31} & q_{41} & q_{51} \\ q_{21} & q_{22} & q_{32} & q_{42} &  q_{52} \\ q_{31} & q_{32} & q_{33} & q_{43} & q_{53} \\ q_{41} & q_{42} & q_{43} & q_{44} & q_{54} \\ q_{51} & q_{52} & q_{53} & q_{54} & q_{55}\\ \end{bmatrix}$$


*Standardized Diagonal Multiplier Form of Q*

The standardized diagonal multiplier or 'std diagonal multiplier' form of the process covariance matrix contain five diagonal elements $\hat{q}_{11}, \hat{q}_{22}, \dots,\hat{q}_{55}$ that are based on a related covariance matrix, but standardized so that the diagonal elements average one, and off-diagonal elements are zero. A multiplicative constant, $q$ is estimated to multiply the standardized diagonal elements. Instead of using a tag to initialize Q, however, this process covariance matrix is explicitly defined as a matrix within the R programming environment with conventions that are compatible with the MARSS software.  The standardization implies that the average of the diagonal terms is one, for comparability of the estimated parameter $q$ with other covariance matrices defined above. In application, numerical values from are substituted for the standardized parameters. For example, if $\hat{q}_{11}$ = 1.23456, the Q matrix would be defined as above with Q = matrix(list('1.23456 * q', 0, 0, 0, 0, ... )).

$$ Q_5 (std \ diagonal \ multiplier) =  \begin{bmatrix} '\hat{q}_{11}*q' & 0 & 0 & 0 & 0 \\ 0 & '\hat{q}_{22}*q' & 0 & 0 & 0 \\ 0 & 0 & '\hat{q}_{33}*q' & 0 & 0 \\ 0 & 0 & 0 & '\hat{q}_{44}*q' & 0 \\ 0 & 0 & 0 & 0 & '\hat{q}_{55}*q'\\ \end{bmatrix}$$

*Measurement Variance $R$*

The random measurement noise scalar time series $v_{t}$ is assumed to be normally distributed with mean 0 and variance $R$. The measurement variance $R$ reflects the uncertainties in discrete measurements of flow.  The scalar value of R can be thought of as a constant for all discrete measurements, or as a time series with accuracies varying among measurements. There are many factors that can affect the accuracy of a streamflow measurement including the type and condition of equipment used, the characteristics of the flow measurement section, how rapidly the stage is changing during the flow measurement, the presence of ice or debris, other environmental conditions during the measurement, and the experience and subjective evaluation by the hydrographer making the measurement [@rantz1982]. The difficulty in quantifying the uncertainty in the field is related to subjectively and consistently assessing the accuracy of the measurement. 

Hydrographers provide qualifiers to describe the precision of discrete flow measurements as: *Excellent,* for measurements thought to be within 2-percent of the actual flow; *Good* for measurements within 5-percent; 'Fair' for measurements within 8-percent, and *Poor* for measurements that may be more than 8 percent from the actual flow. (https://help.waterdata.usgs.gov/codes-and-parameters/discharge-measurement-quality-code). In this analysis, these qualifier were interpreted as 2-, 5-, 8-, and 12-percent standard errors, respectively.  Based on data in table 1, there were no *Excellent* measurements, 210 (`r format(210 / 230 * 100, digits = 3)` percent) *Good* measurements, 16 (`r format(16 / 230 * 100, digits = 2)` percent) *Fair* measurements, and 3 (`r format(3/230 * 100, digits = 3)` percent) *Poor* measurements. An $R_t$ series could be defined as these squared standard errors in percent, or a constant $R$ could be defined as the mean of these variances.  Alternatively, a fixed $R$ could be estimated based on the discrete flow measurements themselves within the MARSS software. All three of these approaches were tested in in the state space models.


$$ R_t(qualifier): Excellent \ R_t = [0.02^2]; \ Good \ R_t = [0.05^2]; \ Fair \ R_t = [0.08^2]; Poor \ R_t = [0.12^2]  $$
$$ R = \bar{r} = mean(R_t[qualifier]) $$ 



$$ R = \hat{r} \: for \ all \ t, \ where \ \hat{r} \ is \ estimated \ in \ MARSS \ based \ on \ the \ discrete \ flow \ data. $$


The design matrix ${Z}_{t}$ is a $10966\times 5$ array series of vectors that form the design matrix. This matrix contains elements of the basis vectors computed from stage data on all days during the period of analysis. The stage data was computed as daily means of unit value stage data, except on days of discrete measurements. On days of discrete measurements, the discrete stage measurement themselves were substituted for the daily mean stage to more precisely correspond to the discrete flow measurements.     

#### Functions used in MARSS (Multivariate Autoregressive State-Space) Modelling 

The function *MARSS* in the **MARSS** package is used to specify the model form and estimate parameters in a state-space model. The syntax of the function *MARSS* is provided below. Arguments to the *MARSS* function that are shown in square brackets have options.  The first option indicated is the default. 

marssObject <- MARSS( Yt, model = list(Z = Zt, A = 'zero', R = R, U = 'zero', Q = Q, x0 = X0, V0 = V0, tinitx=0 ), 
                 control = list( maxit = [ 500 | > 500 ], trace = [0 | 1], conv.test.slope.tol = [0.5 | <0.5] ),
                 method  = [ 'kem' | 'BFGS' ], inits = coef( marssObject0 ). 


| Model Syntax            |  Explanation                                                                                              |  
|:------------------------|:----------------------------------------------------------------------------------------------------------|  
|: marssObject         |: The marss object produced as output from the *MARSS* function. This object contains parameter estimates for the $Q$ and $R$ matrices, Akaikes Information Criteria (AIC), which is an estimator of out of sample prediction error and used in this analysis to select a preferred model, and the log-likelihood, which is a measure of goodness of fit of a statistical model containing unknown parameters. In addition, the Kalman smoothed estimate of daily mean flow, $y_{t}^T$ and its standard error  See [@marss2018] for a complete description of the contents of the marssObject.                                                        |  
|: MARSS( ... )         |: The *MARSS* function is from the R package  **MARSS** and is used to specify the model form and estimate parameters                                         |     
|:  Yt                 |: Yt is an daily time series of the natural logarithms of discrete flow measurements. On days without discrete measurements Yt is missing (NA). In this analysis, Yt is 98.3 percent missing values.                                                                                         |  
|: A, U           |: The A and U vectors are components of the measurement and state equations, respectively, and need to be specified as 'zero' in the model statement, but are nuisance parameters in the context of this analysis. |  
|: R        |: R is the measurement error variance and can be a scalar or time series and can be specified or estimated.  |  
|:                        |:    Cubic Regression Spline [@mgcv2019]                                                                         |  
|: x0         |: x0 is the initial value of the state vector. In this analysis, it is based on the parameters of the GAM model for rating 18, which was used as the initial rating condition. |    
|: data = [rating | discrete pairs  |: The dataframe used in the analysis, with partial listing below this table                                |  
|: V0 |: V0 is the initial value for the state covariance matrix. In this analysis, it was estimated as 1000 times the covariance matrix of parameters in rating 18 estimated by a GAM model. Because the stage-flow data in rating 18 did not include measurement uncertainty, the GAM covariance matrix is unrealistically small. If the covariance is too small, information from discrete measurements will have little effect on the state vector; if the covariance is too large, the state vector might initially change too much in response to discrete flow measurements. It is possible to let the state covariance matrix be estimated entirely from the discrete flow measurements. |
|: tinitx=0 |: The tinitx sets the initial state vector to apply at time zero, just before the first time step with data.  



Several variations of $\vec{x}_t$ are generated by function *MARSSkf* as Kalman filter and smoother output [@marss2018].  These include *xtT*, $x_{t|T}$, which is the smoothed or offline estimate of the state vector at time *t* given all the time steps in the series *T*; *xtt*, $x_{t|t}$, is the filter estimate of the state vector at time *t* given information up to and including time *t*; and *xtt1*, $x_{t|t-1}$ is the predicted state at time *t* given information up to time *t-1*. The state vector was initialized at t = 0 $\vec{x}_{0}$ to the corresponding parameters estimated in a selected GAM model. Like the state vector, the covariance matrix of the state vector has three estimates in MARSS, $V_{t|T}$, $V_{t|t}$, and $V_{t|t-1}$ depending upon whether smoothed, filtered, or prediction variance are of interests. 



## Results of Cubic Spline Regression and State-Space Modeling

### Cubic Regression Splines
 
Genearlized Additive Modeling software [@mgcv2019] was used to develop CRS models describing the relations between stage and flow on Pere Marquette River at Scottville, Mich. for rating periods 18, 19, 20, and 21.  CRSs were developed directly from expanded (0.01 ft increments of stage) ratings and from paired discrete measurements of stage and flow obtained during periods when the ratings were effective. Both methods produced close approximations of the existing rating curves, but there are advantages and disadvantages to both methods. 

In particular, if an existing rating would provide appropriate initial conditions for an adaptive analysis, a GAM-generated CRS can be generated from the extended (0.01 ft increments of stage) rating relation. In the four ratings tested for Pere Marquette River, this fit was almost exact (see R^2^ values for ratings based on the extended stage-flow rating tables (table 3). Preliminary plots showed no discernible differences between the manual rating and the CRS. The limitation of this approach, however, is that confidence limits based on rating table data over-estimates the precision of the relation.  Alternatively, CRSs based on paired discrete stage-flow data provide a close approximation to the rating relation and a more realistic approximation of the uncertainty in the relation. Parameter estimates for the CRSs [$\beta_0$, $\beta_1$, $\beta_3$, and $\beta_4$] were fairly consistent among rating periods. 


```{r gammeasPair_estimate}


# Estimate GAM model for each rating periods
knts = 5; # knts is the number of knots 

# GAM based on rating table
gam18_rating   <- gam( rated_flow        ~ s(stage,             bs = 'cr', k = knts),
                       data = rating18, family = Gamma(link = log)) 

gam19_rating   <- gam( rated_flow        ~ s(stage,             bs = 'cr', k = knts),
                       data = rating19, family = Gamma(link = log))

gam20_rating   <- gam( rated_flow        ~ s(stage,             bs = 'cr', k = knts),
                       data = rating20, family = Gamma(link = log))

gam21_rating   <- gam( rated_flow        ~ s(stage,             bs = 'cr', k = knts),
                       data = rating21, family = Gamma(link = log))

# Summarize GAM of rating-based model
gam18_rating_sum  <- summary(gam18_rating)
gam19_rating_sum  <- summary(gam19_rating)
gam20_rating_sum  <- summary(gam20_rating)
gam21_rating_sum  <- summary(gam21_rating)


# GAM based on discrete stage-flow measurement data 
gam18_measPair <-  gam( flow_discrete_mea ~ s(stage_discrete_mea, bs = 'cr', k = knts), 
                      data = discrete_meas[ discrete_meas$rating == 18, ],
                      family = Gamma(link = log))

gam19_measPair <-  gam( flow_discrete_mea ~ s(stage_discrete_mea, bs = 'cr', k = knts), 
                      data = discrete_meas[ discrete_meas$rating == 19, ],
                      family = Gamma(link = log))

gam20_measPair  <- gam( flow_discrete_mea ~ s(stage_discrete_mea, bs = 'cr', k = knts),
                      data = discrete_meas[ discrete_meas$rating == 20, ],
                      family = Gamma(link = log))


gam21_measPair  <- gam( flow_discrete_mea ~ s(stage_discrete_mea, bs = 'cr', k = knts),
                      data = discrete_meas[ discrete_meas$rating == 21, ],
                      family = Gamma(link = log))


gamPOA_measPair <- gam( flow_discrete_mea ~ s(stage_discrete_mea, bs = 'cr', k = knts),
                      data = discrete_meas,
                      family = Gamma(link = log))

# Compute GAM summary statistics
gam18_measPair_sum  <- summary(gam18_measPair)
gam19_measPair_sum  <- summary(gam19_measPair)
gam20_measPair_sum  <- summary(gam20_measPair)
gam21_measPair_sum  <- summary(gam21_measPair)
gamPOA_measPair_sum <- summary(gamPOA_measPair)


gam_stats <- data.frame('Rating'          = c('18', '19', '20', '21', '18', '19', '20', '21', 'POA'),
                           'N'            = c(gam18_rating_sum$n, gam19_rating_sum$n , gam20_rating_sum$n,
                                              gam21_rating_sum$n, gam18_measPair_sum$n, gam19_measPair_sum$n , 
                                              gam20_measPair_sum$n, gam21_measPair_sum$n, gamPOA_measPair_sum$n),
                           'Residual.df'  =  format(c(gam18_rating_sum$residual.df, gam19_rating_sum$residual.df,
                                                        gam20_rating_sum$residual.df, gam21_rating_sum$residual.df,
                                                        gam18_measPair_sum$residual.df, gam19_measPair_sum$residual.df,
                                                        gam20_measPair_sum$residual.df, gam21_measPair_sum$residual.df,
                                                        gamPOA_measPair_sum$residual.df), digits = 4),
                           'Intercept'      = format(c(gam18_rating$coefficients[1], gam19_rating$coefficients[1],
                                                        gam20_rating$coefficients[1], gam21_rating$coefficients[1],
                                                        gam18_measPair$coefficients[1], gam19_measPair$coefficients[1],
                                                        gam20_measPair$coefficients[1], gam21_measPair$coefficients[1],
                                                        gamPOA_measPair$coefficients[1]), digits = 4),
                           'beta1'      = format(c(gam18_rating$coefficients[2], gam19_rating$coefficients[2],
                                                        gam20_rating$coefficients[2], gam21_rating$coefficients[2],
                                                        gam18_measPair$coefficients[2], gam19_measPair$coefficients[2],
                                                        gam20_measPair$coefficients[2], gam21_measPair$coefficients[2],
                                                        gamPOA_measPair$coefficients[2]), digits = 4),
                           'beta2'      = format(c(gam18_rating$coefficients[3], gam19_rating$coefficients[3],
                                                        gam20_rating$coefficients[3], gam21_rating$coefficients[3],
                                                        gam18_measPair$coefficients[3], gam19_measPair$coefficients[3],
                                                        gam20_measPair$coefficients[3], gam21_measPair$coefficients[3],
                                                        gamPOA_measPair$coefficients[3]), digits = 4),
                           'beta3'      = format(c(gam18_rating$coefficients[4], gam19_rating$coefficients[4],
                                                        gam20_rating$coefficients[4], gam21_rating$coefficients[4],
                                                        gam18_measPair$coefficients[4], gam19_measPair$coefficients[4],
                                                        gam20_measPair$coefficients[4], gam21_measPair$coefficients[4],
                                                        gamPOA_measPair$coefficients[4]), digits = 4),
                           'beta4'      = format(c(gam18_rating$coefficients[5], gam19_rating$coefficients[5],
                                                        gam20_rating$coefficients[5], gam21_rating$coefficients[5],
                                                        gam18_measPair$coefficients[5], gam19_measPair$coefficients[5],
                                                        gam20_measPair$coefficients[5], gam21_measPair$coefficients[5],
                                                        gamPOA_measPair$coefficients[5]), digits = 4),
                           'R2.adj'          = format(c(gam18_rating_sum$r.sq, gam19_rating_sum$r.sq,
                                                        gam20_rating_sum$r.sq, gam21_rating_sum$r.sq,
                                                        gam18_measPair_sum$r.sq, gam19_measPair_sum$r.sq,
                                                        gam20_measPair_sum$r.sq, gam21_measPair_sum$r.sq,
                                                        gamPOA_measPair_sum$r.sq), digits = 4))
# Increment tab_no
tab_no <- tab_no + 1

gam_stats %>% 
  kable( caption = paste('Table', tab_no, '. Summary statistics of five-knot CRSs from Generalized Additive Models for selected rating periods 18 - 20 and the Period of Analysis (POA).' ), 
  col.names = c('Rating period', 'Number of data points', 'Residual degrees of freedom', "beta_0",
                "beta_1", 'beta_2', 'beta_3', "beta_4", 'R^2')) %>% 
  kable_styling() %>% 
  add_header_above( c(' ' = 3, 'Estimated Parameters' = 5, ' ' = 1 ) ) %>% 
  pack_rows('Based on stage-flow rating table', 1, 4) %>% 
  pack_rows('Based on discrete stage-flow measurement', 5, 9) %>% 
  column_spec(1, width = "5em") %>% 
  column_spec(2, width = "5em") %>% 
  column_spec(3, width = "8em")


```



```{r gam_measPair_predict}

# Predicted values are for all stages in rating 21, which has the widest range of the ratings. Note that the predicted values are back-transformed into cubic feet per second from estimation in natural logs. 

gam18_pred <- predict(gam18_measPair, newdata = data.frame( stage_discrete_mea = rating21$stage), se.fit = TRUE,
                       type = 'response')

gam19_pred <- predict(gam19_measPair, newdata = data.frame( stage_discrete_mea = rating21$stage), se.fit = TRUE,
                       type = 'response')

gam20_pred <- predict(gam20_measPair, newdata = data.frame( stage_discrete_mea = rating21$stage), se.fit = TRUE,
                       type = 'response')

gam21_pred <- predict(gam21_measPair, newdata = data.frame( stage_discrete_mea = rating21$stage), se.fit = TRUE,
                       type = 'response')

gamPOA_pred <- predict(gamPOA_measPair, newdata = data.frame( stage_discrete_mea = rating21$stage), se.fit = TRUE,
                       type = 'response')


# Compile and compute gam model results
gam18_df <- data.frame('stage'        = rating21$stage,
                        'gam18_flow'  = gam18_pred$fit, 
                        'gam18_se'    = gam18_pred$se.fit)
gam18_df$ci18_025 <- gam18_df$gam18_flow + qnorm(0.025) * gam18_df$gam18_se
gam18_df$ci18_975 <- gam18_df$gam18_flow + qnorm(0.975) * gam18_df$gam18_se

gam19_df <- data.frame('stage'        = rating21$stage,
                        'gam19_flow'  = gam19_pred$fit, 
                        'gam19_se'    = gam19_pred$se.fit)
gam19_df$ci19_025 <- gam19_df$gam19_flow + qnorm(0.025) * gam19_df$gam19_se
gam19_df$ci19_975 <- gam19_df$gam19_flow + qnorm(0.975) * gam19_df$gam19_se

gam20_df <- data.frame('stage'        = rating21$stage,
                        'gam20_flow'  = gam20_pred$fit, 
                        'gam20_se'    = gam20_pred$se.fit)
gam20_df$ci20_025 <- gam20_df$gam20_flow + qnorm(0.025) * gam20_df$gam20_se
gam20_df$ci20_975 <- gam20_df$gam20_flow + qnorm(0.975) * gam20_df$gam20_se

gam21_df <- data.frame('stage'        = rating21$stage,
                        'gam21_flow'  = gam21_pred$fit, 
                        'gam21_se'    = gam21_pred$se.fit)
gam21_df$ci21_025 <- gam21_df$gam21_flow + qnorm(0.025) * gam21_df$gam21_se
gam21_df$ci21_975 <- gam21_df$gam21_flow + qnorm(0.975) * gam21_df$gam21_se

rating18 <- rating18 %>% 
  rename( rated18_flow = rated_flow) 
rating19 <- rating19 %>% 
  rename( rated19_flow = rated_flow) 
rating20 <- rating20 %>% 
  rename( rated20_flow = rated_flow) 
rating21 <- rating21 %>% 
  rename( rated21_flow = rated_flow) 

gam_df <- gam18_df %>% 
  full_join(gam19_df, by = 'stage') %>% 
  full_join(gam20_df, by = 'stage') %>% 
  full_join(gam21_df, by = 'stage') %>% 
  full_join(rating18, by = 'stage') %>% 
  full_join(rating19, by = 'stage') %>% 
  full_join(rating20, by = 'stage') %>% 
  full_join(rating21, by = 'stage')

gam_long <- gam_df %>% 
  gather( key = 'flow_type', 'flow_cfs', -stage) %>% 
  dplyr::filter( !grepl('_se', flow_type) ) %>% 
  mutate( rating_no = case_when( grepl(18, flow_type) ~ 18,
                                 grepl(19, flow_type) ~ 19,
                                 grepl(20, flow_type) ~ 20,
                                 grepl(21, flow_type) ~ 21)) %>% 
  dplyr::filter( rating_no >= 18 & rating_no <= 21)

ndx_025 <- which( grepl('025', gam_long$flow_type))
gam_long$flow_type[ndx_025] <- 'ci_025'
ndx_975 <- which( grepl('975', gam_long$flow_type))
gam_long$flow_type[ndx_975] <- 'ci_975'
ndx_rat <- which( grepl('rated', gam_long$flow_type ))
gam_long$flow_type[ndx_rat] <- 'rated_flow'
ndx_gam <- which( grepl('gam', gam_long$flow_type))
gam_long$flow_type[ndx_gam] <- 'gam_flow'
  

```

Figure 9 shows the GAM stage-flow ratings for rating periods 18-21 along with 95-percent confidence intervals for the rating line based on the discrete measurements obtained during the rating period.  The corresponding manual rating is shown for comparison along with the discrete measurements for the rating period. The GAM and manual ratings appear fairly consistent for each rating period, despite the fact that the GAM ratings have no information about discrete flow measurements outside the corresponding rating period. The widening confidence interval widths at higher stage show the utility of discrete measurements in reducing the uncertainty of the relation. 

```{r plot_by_rating, fig.height = 10, fig.width = 10}


ndx_rate <- which( discrete_meas$rating_no >= 18 &
                     discrete_meas$rating_no <= 21 & 
                     !is.na(discrete_meas$rating_no) )

fig_no <- fig_no + 1
# Plot manual and gam estimates of each rating curve with corresponding discrete measurements
gam_long %>% 
  ggplot( aes( x = flow_cfs, y = stage, color = flow_type )) +
  geom_line( aes( size = flow_type ), alpha = 0.25 ) +
  facet_wrap( ~ rating_no, ncol = 2 ) +
  theme_bw() +
  scale_color_manual( values = c('forestgreen', 'forestgreen', 'navy', 'red') ) +
  scale_size_manual(  values= c(           1 ,            1,     1.25,  1.25) ) +
  scale_x_continuous( limits = c(0, 10000)) +
  theme( legend.position = 'bottom') +
  geom_point( data = discrete_meas[ndx_rate,], 
               aes( x = flow_discrete_mea, y = stage_discrete_mea, 
                    group = rating_no ), color = 'blue' )  +
  xlab( 'Flow, in cubic feet per second') +
  ylab( 'Stage, in feet above gage datum') +
  ggtitle( label = paste0('Figure ', fig_no, '. Comparison of rating curves created manually with generalized additive models for selected rating periods'))
  
  

# Store GAM parameters in a matrix for comparison
gam_parameters <- matrix(NA, 5, 9)

gam_parameters[ ,1] <- gam18_measPair$coefficients
gam_parameters[ ,2] <- gam19_measPair$coefficients
gam_parameters[ ,3] <- gam20_measPair$coefficients
gam_parameters[ ,4] <- gam21_measPair$coefficients
gam_parameters[ ,5] <- gamPOA_measPair$coefficients

gam_parameters[ ,6] <- gam18_rating$coefficients
gam_parameters[ ,7] <- gam19_rating$coefficients
gam_parameters[ ,8] <- gam20_rating$coefficients
gam_parameters[ ,9] <- gam21_rating$coefficients



gam_parameters_df  <- as.data.frame( gam_parameters )

rownames( gam_parameters_df ) <- c('Knot 1', 'Knot 2', 'Knot 3', 'Knot 4', 'Knot 5')
colnames( gam_parameters_df ) <- c('18', '19', '20', '21' , 'POA',
                                   '18', '19', '20', '21')



```




***

> Basis Functions 

The basis functions developed using the GAM of the rating tables are plotted in figure `r fig_no + 1` along with the knot locations for each model and basis, excluding the (constant) intercept term. The knots are co-located with peak magnitudes of the basis functions. Both the knot locations and the peaks in the basis functions occurred at lower stages for later basis functions. The model.matrix function in the in mgcv software was used to extract the design matrix from the GAM object that results from model estimation.  



```{r plot_basis_functions, fig.width = 11, fig.height = 10}

mm18_rating <- model.matrix(gam18_rating)
basis18_rat <- data.frame(rep('18', nrow(rating18)), rating18$stage, mm18_rating)
colnames(basis18_rat) <- c('Rating', 'Stage', 'Intercept', 'basis1', 'basis2', 'basis3', 'basis4')

mm19_rating <- model.matrix(gam19_rating)
basis19_rat <- data.frame(rep('19', nrow(rating19)), rating19$stage, mm19_rating)
colnames(basis19_rat) <- c('Rating', 'Stage', 'Intercept', 'basis1', 'basis2', 'basis3', 'basis4')

mm20_rating <- model.matrix(gam20_rating)
basis20_rat <- data.frame(rep('20', nrow(rating20)), rating20$stage, mm20_rating)
colnames(basis20_rat) <- c('Rating', 'Stage', 'Intercept', 'basis1', 'basis2', 'basis3', 'basis4')

mm21_rating <- model.matrix(gam21_rating)
basis21_rat <- data.frame(rep('21', nrow(rating21)), rating21$stage, mm21_rating)
colnames(basis21_rat) <- c('Rating', 'Stage', 'Intercept', 'basis1', 'basis2', 'basis3', 'basis4')

basis_rat <- rbind(basis18_rat, rbind(basis19_rat, rbind(basis20_rat, rbind(basis21_rat))))
colnames(basis_rat) <- c('Rating', 'Stage', 'Intercept', 'basis1', 'basis2', 'basis3', 'basis4')
                            
fig_no <- fig_no + 1

knot18 = data.frame( Stage = gam18_rating$smooth[[1]]$xp[2:5],
                                 Basis =  c( 'basis1', 'basis2', 'basis3', 'basis4'))
knot19 = data.frame( Stage = gam19_rating$smooth[[1]]$xp[2:5],
                                 Basis =  c( 'basis1', 'basis2', 'basis3', 'basis4'))
knot20 = data.frame( Stage = gam20_rating$smooth[[1]]$xp[2:5],
                                 Basis =  c( 'basis1', 'basis2', 'basis3', 'basis4'))
knot21 = data.frame( Stage = gam21_rating$smooth[[1]]$xp[2:5],
                                 Basis =  c( 'basis1', 'basis2', 'basis3', 'basis4'))

basis_rat %>% 
  gather( key = 'Basis', value = 'Computed', basis1, basis2, basis3, basis4) %>% 
  mutate( Basis = factor(Basis, levels = c( 'basis1', 'basis2', 'basis3', 'basis4'))) %>% 
  ggplot( aes( x = Stage, y = Computed, color = Rating)) +
  geom_line( aes( size = Rating, alpha = Rating ) ) +
  geom_vline(data = knot18,  aes( xintercept = Stage), color = 'orangered' ) +
  geom_vline(data = knot19,  aes( xintercept = Stage), color = 'yellow4' ) +
  geom_vline(data = knot20,  aes( xintercept = Stage), color = 'aquamarine3' ) +
  geom_vline(data = knot21,  aes( xintercept = Stage), color = 'purple' ) +
  scale_size_manual( values = c( 1, 1, 1, 1, 3 )  ) +
  scale_alpha_manual(values = c( 1, 1, 1, 1, 0.4) ) +
  facet_wrap(. ~ Basis, ncol = 2   ) +
  theme_bw() +
  theme( legend.position = 'bottom') +
  ggtitle( label = paste0('Figure ', fig_no, '. Basis functions of cubic splines approximating selected ratings as a function of stage computed on the basis of discrete flow measurements'),
           subtitle = 'Note: The basis0 equals 1 for all stages and was not included in the plots below' )                     


```


```{r R_variance_distribution, fig.height = 5, eval = FALSE}
# Set up data frame to characterize measurement variances

ndx_ian_Yt <- which(!is.na(df_stage_flow_allDays$flow_discrete_mea) )

  # Initialize measurement error vector with large variance for all days
  R  <- array(0, dim = c(1, 1, nrow(df_stage_flow_allDays)))
  # Measurement variance specification
  #   The standard error of flow as a percentage that varies with perceived accuracy of the measured flow
  R[1,1, ndx_ian_Yt] <- (df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2

data.frame( measurement_variance = R[1, 1, ndx_ian_Yt])  %>% 
  ggplot( aes( x = measurement_variance)) +
  geom_bar( aes(y = (..count..)/sum(..count..)), fill = 'darkgreen', alpha = 0.50 ) + 
  geom_text(aes(y = ((..count..)/sum(..count..)), label = scales::percent((..count..)/sum(..count..))), 
            stat = "count", vjust = -0.25) +
  scale_x_log10( limits = c(1e-3, 5e-2), breaks = c( 0.05^2, 0.08^2, 0.12^2, 0.03) ) +
  scale_y_continuous( labels = scales::percent, limits = c(0, 1) ) +
  geom_vline( xintercept = 300) +
  theme_bw() +
  xlab( 'Measurement variance based on qualifier of discrete flow measurement') +
  ylab( 'Probability density') +
  labs( title = paste0('Figure ', fig_no, '. Frequency density of streamflow measurement variance (R) series based on qualifiers'))

```


### Formatting data for a state space model


```{r set_marss_global_parameters}

# Yt is the measurement vector that contains directly measured flows (not daily means)
Yt <- matrix( log(df_stage_flow_allDays$flow_discrete_mea), nrow = 1)

# Indexes for measured flows in vector
ndx_ian_Yt <- which( !is.na(Yt) )

# Identify days of Discrete Flow Measurement (# # # DFM # # #)
ndx_DFM    <- which( !is.na( df_stage_flow_allDays$flow_discrete_mea ) )

per_NA <- format( length(which( is.na(Yt))) / length(Yt) * 100, digit = 3 )
print(paste('The measurement vector is', 
             per_NA,'percent NA values.'))

############ MODIFY AS NEEDED ###########################
# Substitude discrete stage values for mean daily stage on days of discrete measurement
df_stage_flow_allDays$stage_daily_mean[ ndx_ian ] <- df_stage_flow_allDays$stage_discrete_mea[ ndx_ian ]

Zt <- t(predict( gam18_rating, newdata = data.frame( stage = df_stage_flow_allDays$stage_daily_mean),
                 type = 'lpmatrix') )

# Remove row names
rownames(Zt) <- NULL

# Populate the Zt array in the format that MARSS expects
Zt <- array(Zt, dim = c(1, knts, nrow(df_stage_flow_allDays)))

# A is an unused time-varying vector in the measurement equation
A  <- 'zero'

# Drift vector
U  <- 'zero'

# Initial state vector from GA model
X0 <- as.matrix( as.numeric(coefficients(gam18_rating)), 5, 1)

# Initial covariance of the state model
V0 <- gam18_rating$Vp * 1000

# V0 <- V0 - diag(V0) + c(1,1,1,1,.1) * diag(V0)

```
The R package MARSS [@MARSS2018] was used in developing the state-space model. The notation below follows the authors' notation. 

### State-Space Model

The state-space model [@MARSS2018]

$$
\begin{align}
    \text{State Equation:  }  x_{t} &= {I_n} \: x_{t-1} + w_t && \text{where } w_t \text{~} MVN(0, Q) \text{,}\\
    \text{Measurement Equation:  } y_{t} &= Z_t \text{ } x_{t} + v_t && \text{where } v_t \text{~} N(0, R_{t = t'}) \text{,}\\
    \text{}
\end{align}
$$

Following notation by [@MARSS2018], $y_t$ is the scalar measurement time series, which has a length equal to the number of days in the period of analysis. $y_t$ contains the natural logarithms of discrete flows on days of field measurements. Otherwise, the elements in the vector contain an *NA* value, indicating that a discrete flow measurement was *not available* on that day. In this analysis, $y_t$ contained 98.3 percent *not available* indicators. 

$\vec{x}_t$ is the time series of state vectors, where each vector has a length of 5, corresponding to the number of knots and subsequent parameters specified in the generalized additive model (GAM) CRS equation. Several variations of $\vec{x}_t$ are generated by function *MARSSkf* as Kalman filter and smoother output.  These include *xtT*, which is the smoothed or offline estimate of the state vector at time *t* given all the time steps in the series *T*; *xtt* is the filter estimate of the state vector at time *t* given information up to time *t*; and *xtt1* is the predicted state at time *t* given information up to time *t-1*. 

Q is a $5\times5$ diagonal process variance matrix, which increments the variance *V* of the state vector with each time step in the model.  In the state equation, the process variance indicates the incremental increase in variance of CRS  parameters associated with each day since a discrete measurement of flow occurred. The elements of Q are estimated in the Multivariate Autoregressive State Space (MARSS) model .  To simulate unit flows, the diagonal elements of the Q matrix would be divided by the number of unit values in a day.     

R  is an estimated constant measurement variance


### State-Space Modeling Results


```{r marss_fit_Q_ones_multiplier_R_one_multiplier}

# 1
# Specify model
if( file.exists('marss_fit_Q_ones_multiplier_R_one_multiplier.rds') ){
  marss_fit_Q_ones_multiplier_R_one_multiplier <- read_rds('marss_fit_Q_ones_multiplier_R_one_multiplier.rds')
} else{
  Q = 'diagonal and equal'  # 'ones_multiplier'
  R = 'diagonal and equal'  # 'one_multiplier'
  model.gen=list(Z=Zt,A=A,R=R,U=U,Q=Q,x0=X0,V0=V0,tinitx=0)
  # Refit model: trace = 1 provides parameter etimates with each iteration with the corresponding log-likelihood
  marss_fit_Q_ones_multiplier_R_one_multiplier  <- MARSS(Yt, model = model.gen, control = list(maxit =  5000, trace = 1), 
                                                         method = 'BFGS', 
                                                         inits = coef(marss_fit_Q_ones_multiplier_R_one_multiplier) ) 
  write_rds(marss_fit_Q_ones_multiplier_R_one_multiplier, path = 'marss_fit_Q_ones_multiplier_R_one_multiplier.rds')
}

```


```{r marss_fit_Q_unequal_scalars_R_one_multiplier}
# 2
# Specify model
if( file.exists('marss_fit_Q_unequal_scalars_R_one_multiplier.rds') ){
  marss_fit_Q_unequal_scalars_R_one_multiplier <- read_rds('marss_fit_Q_unequal_scalars_R_one_multiplier.rds')
} else{
  Q = 'diagonal and unequal'  # 'unequal_scalars'
  R = 'diagonal and equal'    # 'one_multiplier'
  model.gen=list(Z=Zt,A=A,R=R,U=U,Q=Q,x0=X0,V0=V0,tinitx=0)
  # Refit model: trace = 1 provides parameter etimates with each iteration with the corresponding log-likelihood
  marss_fit_Q_unequal_scalars_R_one_multiplier  <- MARSS(Yt, model = model.gen, control = list(maxit =  5000, trace = 1), 
                 method = 'BFGS', inits = coef( marss_fit_Q_unequal_scalars_R_one_multiplier ))
  write_rds(marss_fit_Q_unequal_scalars_R_one_multiplier, path = 'marss_fit_Q_unequal_scalars_R_one_multiplier.rds')
}

```


```{r marss_fit_Q_ones_multiplier_R_mean_qualifier}
# 3

# Specify model
if( file.exists('marss_fit_Q_ones_multiplier_R_mean_qualifier.rds') ){
  marss_fit_Q_ones_multiplier_R_mean_qualifier <- read_rds('marss_fit_Q_ones_multiplier_R_mean_qualifier.rds')
} else{
  Q <- 'diagonal and equal'                                                    # 'ones_multiplier'
  # R is specified by qualifiers of discrete flow measurement              
  R  <- matrix(mean( (df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2),1,1)    # 'mean_qualifier'
  model.gen=list(Z=Zt,A=A,R=R,U=U,Q=Q,x0=X0,V0=V0,tinitx=0)
  # Refit model: trace = 1 provides parameter etimates with each iteration with the corresponding log-likelihood
  marss_fit_Q_ones_multiplier_R_mean_qualifier  <- MARSS(Yt, model = model.gen, control = list(maxit =  1000, trace = 1), 
                 method = 'BFGS', inits = coef( marss_fit_Q_ones_multiplier_R_mean_qualifier ))
  write_rds(marss_fit_Q_ones_multiplier_R_mean_qualifier, path = 'marss_fit_Q_ones_multiplier_R_mean_qualifier.rds')
}


```


```{r marss_fit_Q_unconstrained_R_mean_qualifier}
# 4

# Specify model
if( file.exists('marss_fit_Q_ones_multiplier_R_mean_qualifier.rds') ){
  marss_fit_Q_unconstrained_R_mean_qualifier <- read_rds('marss_fit_Q_unconstrained_R_mean_qualifier.rds')
} else{
  Q <- 'unconstrained'                                                    # 'ones_multiplier'
  # R is specified by qualifiers of discrete flow measurement              
  R  <- matrix(mean( (df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2),1,1)    # 'mean_qualifier'
  model.gen=list(Z=Zt,A='zero',U='zero',R=R,Q=Q,x0=X0,V0=V0,tinitx=0)
  # Refit model: trace = 1 provides parameter etimates with each iteration with the corresponding log-likelihood
  marss_fit_Q_unconstrained_R_mean_qualifier  <- MARSS(Yt, model = model.gen, control = list(maxit =  1000, trace = 1), 
                 method = 'BFGS', inits = coef( marss_fit_Q_unconstrained_R_mean_qualifier ))
  write_rds(marss_fit_Q_unconstrained_R_mean_qualifier, path = 'marss_fit_Q_unconstrained_R_mean_qualifier.rds')
}


```


```{r marss_fit_Q_equalvarcov_R_mean_qualifier}
# 5

# Specify model
if( file.exists('marss_fit_Q_equalvarcov_R_mean_qualifier.rds') ){
  marss_fit_Q_equalvarcov_R_mean_qualifier <- read_rds('marss_fit_Q_equalvarcov_R_mean_qualifier.rds')
} else{
  Q <- 'equalvarcov'                                                    # 'ones_multiplier'
  # R is specified by qualifiers of discrete flow measurement              
  R  <- matrix(mean( (df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2),1,1)    # 'mean_qualifier'
  model.gen=list(Z=Zt,A=A,R=R,U=U,Q=Q,x0=X0,V0=V0,tinitx=0)
  # Refit model: trace = 1 provides parameter etimates with each iteration with the corresponding log-likelihood
  marss_fit_Q_equalvarcov_R_mean_qualifier  <- MARSS(Yt, model = model.gen, 
                                                     control = list(maxit =  5000, conv.test.slope.tol = 0.05), 
                 method = 'kem',  inits = coef(marss_fit_Q_equalvarcov_R_mean_qualifier))
  write_rds(marss_fit_Q_equalvarcov_R_mean_qualifier, path = 'marss_fit_Q_equalvarcov_R_mean_qualifier.rds')
}


```


```{r marss_fit_Q_covar_multiplier_R_one_multiplier}

# 6

# Standardize the diagonal of gam18_rating for estimation
#  These standardized variance terms average 1 and form the diagonal of Q
gam18_diag_std <- diag(gam18_rating$Vp)/mean(diag(gam18_rating$Vp))

if( file.exists( 'marss_fit_Q_covar_multiplier_R_one_multiplier.rds' )){
  marss_fit_Q_covar_multiplier_R_one_multiplier <- read_rds( 'marss_fit_Q_covar_multiplier_R_one_multiplier.rds' )
} else {
  # State variance matrix is based on the gam18_measPair$Vp
  Q <- matrix(list('0.1166336*q',0,0,0,0,                 # 'covar_multiplier'
                   0,'1.3179593*q',0,0,0  ,
                   0,0,'0.6810473*q',0,0,
                   0,0,0,'1.0737010*q',0,
                   0,0,0,0,'1.8106588*q'), 5, 5)
  R  <- 'diagonal and equal'                              # 'one_multiplier'
  
  # Specify model
  model.gen=list(Z=Zt,A=A,R=R,U=U,Q=Q,x0=X0,V0=V0,tinitx=0)
  
  # Refit model: trace = 1 provides parameter etimates with each iteration with the corresponding log-likelihood
  marss_fit_Q_covar_multiplier_R_one_multiplier  <- MARSS(Yt, model = model.gen, control = list(maxit =  1000, trace = 1), 
                                                            method = 'BFGS',
                                                          inits = coef(marss_fit_Q_covar_multiplier_R_one_multiplier))
  
  write_rds(marss_fit_Q_covar_multiplier_R_one_multiplier, path = 'marss_fit_Q_covar_multiplier_R_one_multiplier.rds')
}

```





```{r marss_fit_Q_covar_multiplier_R_mean_qualifier}

# 7

# Standardize the diagonal of gam18_rating for estimation
#  These standardized variance terms average 1 and form the diagonal of Q
# gam18_diag_std <- diag(gam18_rating$Vp)/mean(diag(gam18_rating$Vp))

if( file.exists( 'marss_fit_Q_covar_multiplier_R_mean_qualifier.rds' )){
  marss_fit_Q_covar_multiplier_R_mean_qualifier <- read_rds( 'marss_fit_Q_covar_multiplier_R_mean_qualifier.rds' )
} else {
  # State variance matrix is based on the gam18_measPair$Vp
  Q <- matrix(list('0.1166336*q',0,0,0,0,                                     # 'covar_multiplier'
                   0,'1.3179593*q',0,0,0  ,
                   0,0,'0.6810473*q',0,0,
                   0,0,0,'1.0737010*q',0,
                   0,0,0,0,'1.8106588*q'), 5, 5)
  
  # R is specified by qualifiers of discrete flow measurement
  R  <- matrix(mean( (df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2),1,1)   # 'mean_qualifier'
  
  # Specify model
  model.gen=list(Z=Zt,A=A,R=R,U=U,Q=Q,x0=X0,V0=V0,tinitx=0)
  
  # Refit model: trace = 1 provides parameter etimates with each iteration with the corresponding log-likelihood
  marss_fit_Q_covar_multiplier_R_mean_qualifier  <- MARSS(Yt, model = model.gen, control = list(maxit =  1000, trace = 1), 
                                                            method = 'BFGS',
                                                          inits = coef(marss_fit_Q_covar_multiplier_R_mean_qualifier))
  
  write_rds(marss_fit_Q_covar_multiplier_R_mean_qualifier, path = 'marss_fit_Q_covar_multiplier_R_mean_qualifier.rds')
}


```

summary(marss_fit_Q_covar_multiplier_R_mean_qualifier)

```{r marss_fit_Q_ones_multiplier_R_series_qualifier}

# 8

if ( file.exists( 'marss_fit_Q_ones_multiplier_R_series_qualifier.rds' )){
  marss_fit_Q_ones_multiplier_R_series_qualifier <- read_rds( 'marss_fit_Q_ones_multiplier_R_series_qualifier.rds' )
} else {
  Q = 'diagonal and equal'                                                      # 'ones_multiplier'
  
  # Initialize measurement error vector with large variance for all days        # 'series_qualifier'
  R  <- array(0, dim = c(1, 1, nrow(df_stage_flow_allDays)))
  # Measurement variance specification
  #   The standard error of flow as a percentage that varies with perceived accuracy of the measured flow
  R[1,1, ndx_ian_Yt] <- (df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2
  
  # Specify model
  model.gen=list(Z=Zt,A=A,R=R,U=U,Q=Q,x0=X0,V0=V0,tinitx=0)
  
  # Refit model: trace = 1 provides parameter etimates with each iteration with the corresponding log-likelihood
  marss_fit_Q_ones_multiplier_R_series_qualifier  <- MARSS(Yt, model = model.gen, method = 'kem',
                                         control = list(maxit =  1000, trace = 1, conv.test.slope.tol = 0.05),
                                         inits = coef(marss_fit_Q_ones_multiplier_R_series_qualifier))
  
  write_rds(marss_fit_Q_ones_multiplier_R_series_qualifier, path = 'marss_fit_Q_ones_multiplier_R_series_qualifier.rds')
}


```


```{r marss_fit_Q_covar_multiplier_R_series_qualifier}

# 9

# Standardize the diagonal of gam18_rating for estimation
# gam18_diag_std <- diag(gam18_rating$Vp)/mean(diag(gam18_rating$Vp))

if( file.exists( 'marss_fit_Q_covar_multiplier_R_series_qualifier.rds' )){
  marss_fit_Q_covar_multiplier_R_series_qualifier <- read_rds( 'marss_fit_Q_covar_multiplier_R_series_qualifier.rds' )
} else {
  # State variance matrix is based on the gam18_measPair$Vp
  Q <- matrix(list('0.1166336*q',0,0,0,0,                                  # 'covar_multiplier'
                   0,'1.3179593*q',0,0,0  ,
                   0,0,'0.6810473*q',0,0,
                   0,0,0,'1.0737010*q',0,
                   0,0,0,0,'1.8106588*q'), 5, 5)
  
  # Initialize measurement error vector with large variance for all days
  R  <- array(0, dim = c(1, 1, nrow(df_stage_flow_allDays)))               # 'series_qualifier'
  # Measurement variance specification
  #   The standard error of flow as a percentage that varies with perceived accuracy of the measured flow
  R[1,1, ndx_ian_Yt] <- (df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2
  
  # Specify model
  model.gen=list(Z=Zt,A=A,R=R,U=U,Q=Q,x0=X0,V0=V0,tinitx=0)
  
  # Refit model: trace = 1 provides parameter etimates with each iteration with the corresponding log-likelihood
  marss_fit_Q_covar_multiplier_R_series_qualifier  <- MARSS(Yt, model = model.gen, control = list(maxit =  4000, 
                                                            conv.test.slope.tol = 0.05), method = 'kem',
                      inits = coef(marss_fit_Q_covar_multiplier_R_series_qualifier))
  
  write_rds(marss_fit_Q_covar_multiplier_R_series_qualifier, path = 'marss_fit_Q_covar_multiplier_R_series_qualifier.rds')
}

```

```{r marss_fit_Q_diag_unequal_R_series_specified_var}

# 10

if ( file.exists( 'marss_fit_Q_diag_unequal_R_series_specified_var.rds' )){
  marss_fit_Q_diag_unequal_R_series_specified_var <- read_rds( 'marss_fit_Q_diag_unequal_R_series_specified_var.rds' )
} else {
  Q = 'diagonal and unequal'  
  
  # Initialize measurement error vector with large variance for all days        # 'series_qualifier'
  R  <- array(0, dim = c(1, 1, nrow(df_stage_flow_allDays)))
  # Measurement variance specification
  #   The standard error of flow as a percentage that varies with perceived accuracy of the measured flow
  R[1,1, ndx_ian_Yt] <- (df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2
  
  # Specify model
  model.gen=list(Z=Zt,A=A,R=R,U=U,Q=Q,x0=X0,V0=V0,tinitx=0)
  
  # Refit model: trace = 1 provides parameter etimates with each iteration with the corresponding log-likelihood
  marss_fit_Q_diag_unequal_R_series_specified_var  <- MARSS(Yt, model = model.gen, method = 'kem',
                            control = list(maxit =  2000, trace = 0, conv.test.slope.tol = 0.05),
                            inits = marss_fit_Q_diag_unequal_R_series_specified_var)
  
  write_rds(marss_fit_Q_diag_unequal_R_series_specified_var, path = 'marss_fit_Q_diag_unequal_R_series_specified_var.rds')
}
```



#### Summary of All State-Space Modeling Results 

```{r state_space_compare}

Model_01 <- read_rds('marss_fit_Q_ones_multiplier_R_one_multiplier.rds')
Model_02 <- read_rds('marss_fit_Q_unequal_scalars_R_one_multiplier.rds')
Model_03 <- read_rds('marss_fit_Q_ones_multiplier_R_mean_qualifier.rds')
Model_04 <- read_rds('marss_fit_Q_unconstrained_R_mean_qualifier.rds')
Model_05 <- read_rds('marss_fit_Q_equalvarcov_R_mean_qualifier.rds')
Model_06 <- read_rds('marss_fit_Q_covar_multiplier_R_one_multiplier.rds')
Model_07 <- read_rds('marss_fit_Q_covar_multiplier_R_mean_qualifier.rds')
Model_08 <- read_rds('marss_fit_Q_ones_multiplier_R_series_qualifier.rds')
Model_09 <- read_rds('marss_fit_Q_covar_multiplier_R_series_qualifier.rds')

# Set up data.frame to compare models,
marss_compare <- data.frame(
  Q.Process     = c('diagonal and equal', 'diagonal and unequal', 'diagonal and equal', 'unconstrained', 'equalvarcov',
                    'standardized diagonal multiplier', 'standardized diagonal multiplier', 'diagonal and equal',
                    'standardized diagonal multiplier' ) ,
  R.Measurement = c('diagonal and equal', 'diagonal and equal',  'mean specified variance', 'mean specified variance', 
                    'mean specified variance', 'diagonal and equal', 'mean specified variance', 
                    'series specified variance', 'series specified variance' ) ,
  'Method'         = c( 'BFGS', 'BFGS', 'BFGS', 'BFGS', 'kem', 'BFGS', 'BFGS', 'kem', 'kem' ),
  'Q_Process'      = format(c( 
                       mean(diag(Model_01$par$Q)), 
                       mean(diag(Model_02$par$Q)),
                       mean(diag(Model_03$par$Q)), 
                       mean(diag(Model_04$par$Q)),
                       mean(diag(Model_05$par$Q)),
                       mean(diag(Model_06$par$Q)),
                       mean(diag(Model_07$par$Q)),
                       mean(diag(Model_08$par$Q)),
                       mean(diag(Model_09$par$Q))), digits = 4), 
  'R_Measurement'  = c(format(Model_01$par$R, digits = 4),
                       format(Model_02$par$R, digits = 4),
                       format(mean(df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2, digits = 4),
                       format(mean(df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2, digits = 4),
                       format(mean(df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2, digits = 4),
                       format(Model_06$par$R, digits = 4),
                       format(mean(df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2, digits = 4),
                       format(mean(df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2, digits = 4),
                       format(mean(df_stage_flow_allDays$se_pct[ndx_ian_Yt]/100)^2, digits = 4)),
  'Likelihood'     = format(c(Model_01$logLik, 
                              Model_02$logLik,
                              Model_03$logLik,
                              Model_04$logLik,
                              Model_05$logLik,
                              Model_06$logLik,
                              Model_07$logLik,
                              Model_08$logLik,
                              Model_09$logLik), digits = 4),
  'AIC'            = format(c(Model_01$AIC,
                              Model_02$AIC,
                              Model_03$AIC,
                              Model_04$AIC,
                              Model_05$AIC,
                              Model_06$AIC,
                              Model_07$AIC,
                              Model_08$AIC,
                              Model_09$AIC), digits = 4),
  'no_Q_parm'     = c( length(Model_01$par$Q),  length(Model_02$par$Q), length(Model_03$par$Q),  
                       length(Model_04$par$Q),  length(Model_05$par$Q), length(Model_06$par$Q),  
                       length(Model_07$par$Q),  length(Model_08$par$Q), length(Model_09$par$Q)), 
  'no_R_parm'     = c( length(Model_01$par$R),  length(Model_02$par$R), length(Model_03$par$R),  
                       length(Model_04$par$R),  length(Model_05$par$R), length(Model_06$par$R),
                       length(Model_07$par$R),  length(Model_08$par$R), length(Model_09$par$R)))
                                               
  
tab_no <- tab_no + 1                 
marss_compare %>%
  mutate( Model = seq(1, 9)) %>% 
  arrange( AIC ) %>% 
  # mutate( Model = seq( 1, nrow( marss_compare ))) %>% 
  dplyr::select( Model, everything() ) %>% 
  kable( caption = paste0('Table ', tab_no,'. Summary statistics from Multivariate Autoregressive State-Space Models of Flow.'),
         col.names = c('Model', 'Process, Q', 'Measure-ment, R', 'Parameter Estima-tion Method', 
                       'Process, Q', 'Measure-ment, R','Log-likeli-hood', 'Akaike Infor-mation Criteria',
                       'Q', 'R')) %>% 
  kable_styling( position = 'center', latex_options = 'scale down') %>% 
  column_spec( 1, width = '8em' ) %>% 
  column_spec( 2, width = '8em' ) %>% 
  column_spec( 3, width = '8em' ) %>%
  column_spec( 5, width = '8em' ) %>% 
  column_spec( 6, width = '8em' ) %>% 
  column_spec( 8, width = '8em' ) %>% 
  column_spec( 9, width = '8em' ) %>% 
  column_spec(10, width = '8em' ) %>% 
  add_header_above( c(' ' = 1, 'Variance Structure' = 2, ' ' ,'Variance Estimates' = 2, 
                      ' ' = 1, ' ' = 1, 'Number of Parameters' = 2), align = 'center') %>% 
  footnote(general = c('log-likelihood, a goodness of fit statistic that is maximized in model selection,',
           'AICc: Akaike Information Criteria is a measure of out-of-sample prediction error that is minimized in model selection.',
           'SE Qualifier: Standard Error of Measurement Qualifier, in percent. Excellent = 2%, Good = 5%, Fair = 8%, and Poor = 12%',
           'Process Variance Q estimated as 5 x 5 diagonal matrix with equal variances.',
           'BFGS: BroydenFletcherGoldfarbShanno quasi Newton parameter estimation algorithm.',
           'kem:  kernelized expectation-maximization algorithm for parameter estimation.'))
             
  




```

## Application of the Selected State-Space Model

```{r eval_state_space}

# Select model 3 for analysis
# marss_fit   <- marss_fit_QdiagUnequal_Rseries
# marss_fit <- marss_fit_QdiagEqual_RdiagEqual
marss_fit   <- marss_fit_Q_ones_multiplier_R_series_qualifier
marss_kf    <- MARSSkf( marss_fit )
marss_kfss  <- MARSSkfss( marss_fit )
# kfss function provids Innov, J, J0, Kt, Sigma, Vtt
# marss_kfss  <- MARSSkfss( marss_fit )
  


df_stage_flow_allDays$ytT    <- marss_fit$ytT[1, ]

df_stage_flow_allDays$ytT.se <- marss_fit$ytT.se[, ]

# df_stage_flow_allDays$Kt     <- marss_kfss$Kt

df_stage_flow_allDays <- addWaterYear(df_stage_flow_allDays)

df_stage_flow_allDays <- df_stage_flow_allDays %>% 
  mutate( cl025 = ytT + qnorm( 0.025 ) * ytT.se ,
          cl975 = ytT + qnorm( 0.975 ) * ytT.se ) 

```


### Changes in Cubic Spline Regression Parameters with Discrete Measurements    


```{r, state_parameter_matrix, fig.height = 9, fig.width = 9 }

# marss_state_tT is the estimate of the state at time t given all time T
marss_state_tT           <- data.frame( t(as.matrix( marss_kf$xtT, ncol = 5, nrow = 10966)))
marss_state_tT$Date      <- flow_daily_pub$Date
colnames(marss_state_tT) <- c('x1 (b0)', 'x2 (b1)', 'x3 (b2)', 'x4 (b3)', 'x5 (b4)', 'Date')

# Identify days of Discrete Flow Measurement (# # # DFM # # #)
ndx_DFM <- which( !is.na( df_stage_flow_allDays$flow_discrete_mea ) )

fig_no <- fig_no + 1
marss_state_tT %>% 
  gather( key = 'Parameter', value = 'Estimate', -Date) %>% 
  ggplot( aes( x = Date, y = Estimate, group = Parameter )) +
  geom_line() +
  geom_vline( xintercept = df_stage_flow_allDays$Date[ ndx_DFM ], color = 'lightblue' ) +
  theme_bw() +
  xlab( 'Date') + 
  ylab( 'State Estimates') +
  theme( legend.position = 'bottom') +
  facet_wrap( ncol = 1, Parameter ~ ., scales = 'free' ) +
  ggtitle( label = paste0('Figure ', fig_no, '. Daily estimates of the state vector as parameters of the corresponding basis functions.') ,
           subtitle = 'Vertical lines indicate dates of discrete flow measurements.')



```

### Stage-Flow Rating Adaptions with Discrete Measurements  


```{r adaptive_rating, fig.height = 16, fig.width = 9}
# Design matrix for allDays

sel_yr <- seq(from = 1992, to = 2019, by = 3)

# Design matrix formed with from Rating 18 basis functions using the stage range in Rating 21
#   The range in stage is the widest range of stage (0.53 - 8.10 ft)
design_matrix_rating <- predict( gam18_rating,  newdata = data.frame( stage = rating21$stage), 
                                 type = 'lpmatrix')


# Design matrix for rating augmented with corresponding stage
stage_design_matrix_rating <- cbind(rating21$stage, design_matrix_rating) 
colnames(stage_design_matrix_rating)[1] <- 'stage'

# Preallocate matrix to contain time-varying flows at times of dDscrete Flow Measurement (DFM)
flow_rating_DFM <- matrix(NA, nrow = nrow(rating21), ncol = length( ndx_DFM ) )

# design_matrix <- as.matrix(design_matrix_rating[,1:5])

for (i in 1:length(ndx_DFM )){
  flow_rating_DFM[ , i ] <- exp( design_matrix_rating %*% matrix( marss_kf$xtT[ , ndx_DFM[ i ]], 5, 1 ) )
}


flow_rating_DFM_vec <- matrix( flow_rating_DFM, ncol = 1, byrow = FALSE)

adaptive_rating_measDays <- data.frame( Date       = rep(df_stage_flow_allDays$Date[ ndx_DFM ], each  = nrow(   rating21)),
                                        stage      = rep(rating21$stage,                        times = length( ndx_DFM )),
                      marss_flow = flow_rating_DFM_vec )
adaptive_rating_measDays <- adaptive_rating_measDays %>% addWaterYear()


discrete_meas_allDays <- discrete_meas %>% 
  left_join( df_stage_flow_allDays, by = 'Date' )

# Find indices of allDays in which discrete flow measurements occurred
ndx_allDays_measDays <- which( df_stage_flow_allDays$Date %in% discrete_meas$Date )


tmp <- df_discrete_meas %>%
  # mutate( Date = measurement_dt ) %>% 
  addWaterYear() %>% 
  filter( waterYear %in% sel_yr)


adaptive_rating_measDays %>% 
  dplyr::filter( waterYear %in% sel_yr) %>%
  arrange( marss_flow ) %>% 
  ggplot( aes(x = marss_flow, y = stage, group = waterYear ), alpha = 0.25) +
  geom_line(  aes( x = marss_flow, y = stage), size = 0.25, color = 'blue', alpha = 0.5) +
  # geom_point( aes( x = discrete_meas$Date, y = discrete_meas$flow_discrete_mea, 
  #        ), color = 'blue') +
  labs(title = 'Date of Measurement:' ) + 
  theme_bw() +
  facet_wrap( ~ waterYear, ncol = 2) +
  theme( legend.position = 'right') +
  xlab( 'Streamflow, in cubic feet per second' ) +
  ylab( 'Stage, in feet above gage datum' ) + 
  labs(title = 'Stage-Flow Ratings at 04122500 Pere Marquette River at Scottville, MI') +
  geom_line( data = rating18, aes( x = rated18_flow, y = stage, group = NULL), color = 'red', size = 0.5 ) +
  geom_line( data = rating21, aes( x = rated21_flow, y = stage, group = NULL), color = 'forestgreen', size = 0.5 ) +
  geom_point( data = tmp, aes( x = flow_discrete_mea, y = stage_discrete_mea, color = factor(waterYear))) +
  theme( legend.position = 'bottom')

```


### Streamflow Magnitude and Uncertainty Computed by Kalman filter for the Selected State-Space Model  



```{r plot_daily_flow_se, fig.width = 12, fig.height = 20 }
sel_yr <- seq(from = 1990, to = 2019, by = 3)

df_stage_flow_allDays %>% 
  dplyr::filter( waterYear %in% sel_yr ) %>% 
  mutate( y_ice = pmin(flow_daily_pub, exp(ytT)) ) %>%  
  ggplot( aes( x = Date  )) +
  geom_line( aes( y = exp(ytT) ), color = 'red' ) +
  geom_point(aes( y = flow_discrete_mea,   color = qualifier), size = 1.5 ) +
  geom_point(aes( y = flow_discrete_mea ), size = 5, shape = 1, color = 'black'  ) +
  geom_line( aes( y = exp(cl025) ), color = 'blue', size = 0.5) +
  geom_line( aes( y = exp(cl975) ), color = 'blue', size = 0.5) +
  geom_line(  aes( y = flow_daily_pub ), color = 'darkgreen', size = 0.7) +
  geom_ribbon( aes(ymin = y_ice, ymax = exp(ytT) ), fill = 'grey', alpha = 0.5  ) +
  theme_bw() +
  scale_y_log10() +
  xlab( 'Date') + 
  ylab( 'Daily mean streamflow, in cubic feet per second') +
  theme( legend.position = 'bottom') +
  facet_wrap( ncol = 2, waterYear ~ ., scales = 'free' ) +
  ggtitle( 'Figure x. Daily mean expected streamflow (red) with 95-percent confidence intervals (blue) based on adaptive spline \nrating model with historically published streamflow (green).',
           subtitle = 'Grey filled areas between published and expected daily flow primarily show ice affects.')


```


```{r kalman_estimators, fig.height = 6, fig.width = 7}

Z <- predict( gam18_rating, newdata = data.frame( stage = rating18$stage ),
              type = 'lpmatrix')

# marss_fit_Q_ones_multiplier_R_series_qualifier
Zt <- t(predict( gam18_rating, newdata = data.frame( stage = df_stage_flow_allDays$stage_daily_mean),
                 type = 'lpmatrix') )

Zt <- array(Zt, dim = c(1, knts, nrow(df_stage_flow_allDays)))

xtt1 <- marss_kfss$xtt1
xtt  <- marss_kfss$xtt
xtT  <- marss_kfss$xtT

ytt1 <- matrix(NA, dim(xtt1))
ytt  <- matrix(NA, dim(xtt))
ytT  <- matrix(NA, dim(xtT))


for (t in 1:nrow(df_stage_flow_allDays)){
  ytt1[t] <- Zt[,,t] %*% xtt1[, t, drop = F]
  ytt[t]  <- Zt[,,t] %*% xtt[ , t, drop = F]
  ytT[t]  <- Zt[,,t] %*% xtT[ , t, drop = F]
}

# Measured values of flow
ytt1_DFM  <- ytt1[ndx_DFM]
ytt_DFM   <- ytt[ ndx_DFM]
ytT_DFM   <- ytT[ ndx_DFM]

ytm_DFM   <- log( df_stage_flow_allDays$flow_discrete_mea[ndx_DFM] )


ett1_DFM  <- ytt1_DFM - ytm_DFM 
ett_DFM   <- ytt_DFM  - ytm_DFM 
etT_DFM   <- ytT_DFM  - ytm_DFM 

df_DFM <- data.frame(Date = df_stage_flow_allDays$Date[ndx_DFM],
                     ytm  = exp(ytm_DFM),
                     ytt1 = exp(ytt1_DFM), ytt = exp(ytt_DFM), ytT = exp(ytT_DFM),
                     ett1 = ett1_DFM, ett = ett_DFM, etT = etT_DFM )

lmtt1 <- summary(with(df_DFM, lm(ytt1 ~ ytm)))
lmtt  <- summary(with(df_DFM, lm(ytt  ~ ytm)))
lmtT  <- summary(with(df_DFM, lm(ytT  ~ ytm)))
```

** Kalman Estimators **  
Three Kalman estimates are include in this analysis: forecast $\hat{y}_{t}^{t-1}$ , filtered $\hat{y}_{t}^{t}$, and smoothed. $\hat{y}_{t}^{T}$.  The forecast or, on days of discrete measurement, filtered estimates may be considered real-time values in the sense that as soon as the unit (or daily) stage data becomes available, a Kalman estimate of flow can be computed. The smoothed estimated, however, can be modified by discrete measurements that come after the time of estimation, and may be referred to as off-line estimates. In particular, the accuracy of smoothed forecast estimates made one or more days prior to a discrete measurement may be improved by the waiting for information contained in discrete measurements available subsequent to the time of estimation.   
 
Overall, the agreement between discrete flow measurements and Kalman estimates of flow is close. In particular, the coefficient of determination between logarithms of measured and forecast flows ($R_{forecast}^2$) is `r format(lmtt1$adj.r.squared, digits = 4)`; between measured and filtered flows ($R_{filtered}^2$) is `r format(lmtt$adj.r.squared, digits = 4)`; and between measured and smoothed flows ($R_{smoothed}^2$) is `r format( lmtT$adj.r.squared, digits = 4)`.  Close inspection of fig. `r fig_no + 1 ` confirms, however, that the forecast measurements (red circles) are consistently further from the line of agreement than filtered estimates that are made 1 time step later. The filtered estimates show little apparent difference in accuracy, however, than the smoothed estimates.  Thus, information that is obtained on average 56.6 days (fig. 4) after a discrete measurement have little effect on accuracy.  Intervening times of estimation between between discrete measurements may, however, have substantially improved accuracies.    


```{r  kalman_estimators_plt, fig.height = 6, fig.width = 7}
fig_no <- fig_no + 1

df_DFM[, c('Date', 'ytm', 'ytt1', 'ytt', 'ytT')] %>% 
  rename(Forecast = ytt1, Filtered = ytt, Smoothed = ytT) %>% 
  gather(key = 'Kalman_estimator', value = 'Flow_cfs', Forecast, Filtered, Smoothed,
         -Date, -ytm, factor_key = TRUE) %>% 
  ggplot( aes( x = ytm, y = Flow_cfs, shape = Kalman_estimator )) +
  geom_point( aes( color = Kalman_estimator )) +
  scale_shape_manual( values = c(1, 3, 4)) +
  scale_color_manual( values = c('red', 'olivedrab', 'slateblue1')) +
  theme_bw() +
  geom_abline( intercept = 0, slope = 1) +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = 'Discrete Flow Measurement, in cubic feet per second',
       y = 'Kalman Estimate of Flow, in cubic feet per second') +
  theme( legend.position = 'bottom' ) + 
  ggtitle( label = paste0('Figure ', fig_no, '. Relation between measured discrete flow and Kalman estimates'))

```

** Kalman Estimation Errors **

Figure `r fig_no+ 1 ` shows the distribution of Kalman forecast $y_t^m - \hat{y}_t^{t-1} $, filtered $y_t^m - \hat{y}_t^{t} $, and smoothed errors $y_t^m - \hat{y}_t^{T} $, where $y_t$ equals the natural logarithm of flow at time $t$, the superscripts refers to the information available at the time of measurement.  Here, $m$ implies the discrete flow measurement, $t-1$ implies one day prior to the discrete measurement, $t$ implies the time of the discrete measurement, and $T$ implies all time in the period of analysis. The forecast error reflect the largest uncertainty (greatest difference between the 75^th^ and 25^th^ percentiles because the forecast is based only on information available the day before the corresponding discrete measurement. The filtered estimate includes information up to and including information on the day of measurement. The smoothed estimate contains information available throughout the period of analysis, but shows little change in uncertainty from the filtered estimate.  Thus, there is little transfer of information to information at time $t$ from information at time $t+E[\Delta{t}]$, where $E\Delta{t}$ equals 56.6 days (fig. 4).   


```{r boxplot_err, fig.height = 6, fig.width = 7}

fig_no <- fig_no + 1

df_DFM[, c('Date', 'ett1', 'ett', 'etT')] %>% 
  rename(Forecast = ett1, Filtered = ett, Smoothed = etT) %>% 
  gather(key = 'Estimator', value = 'Flow_error_log', Forecast, Filtered, Smoothed,
         -Date, factor_key = TRUE) %>% 
  ggplot( aes( x = Estimator, y = Flow_error_log )) +
  geom_boxplot() +
  theme_bw() +
  geom_hline( yintercept = 0, linetype = 'dashed' , color = 'salmon') +
  xlab( 'Kalman Estimator' ) +
  ylab( 'Difference between natural logarithms of \ndiscrete flow measurements and Kalman estimates') +
  ggtitle( label = paste0('Figure ', fig_no, '. Boxplots comparing the distribution of errors in logarithms of flow for \n Kalman forecast, filtered, and smoothed estimates' ) )



```




## Summary and Conclusions   

Cubic Spline Regressions (CSRs) were developed in a generalized additive modelling environment to estimate stage-flow relations during rating periods 18 through 21 for USGS streamgage 04122500 Pere Marquette River at Scottville, Mich.  Regressions for all rating periods were developed using stage-flow data from expanded (0.01 ft increments of stage) rating tables, and from pairs of discrete stage and flow measurements obtained during the corresponding rating period.  The curves formed by the CRSs and the rating tables matched closely as indicated by a coefficient of determination (R^2^ value) of approximately 1. The indicated uncertainties of these CRSs curves, however, were uninterpretable because the uncertainty measures was heavily influenced by the arbitrary discretization interval (0.01 ft) for the stage data. Still, the parameters of these rating curves may have utility in automatically adapting existing stage-flow relations developed manually to on-going stage-flow changes with subsequent discrete measurement data.  

CSRs also were developed by use of paired stage-flow discrete measurement data obtained during the corresponding rating period. These regressions also approximated the  
 

The Cubic Spline Regessions (CSRs) developed within a generalized additive modelling (GAM) framework provided a flexible and accurate method for estimating the stage-flow relation at a streamgage either directly from an expanded stage-flow rating table, or from discrete pairs of stage-flow measurements. The GAM environment produced a set of parameter estimates for the CSRs and a method for generating basis vectors from stage data.  The CSR parameters were used as the state vector in the state equation of a state-space model. The set basis vectors formed a design matrix that premultiplied the state vector in the measurement equation to compute flow.  The process variance matrix $Q$ in the state equation and measurement variance $R$ in the measurement equation were estimated by use of discrete measurements of stage and flow.  


Conclusions  


## Appendix 1. Full printout of all estimated Generalized Additive Models (GAM) for Ratings 18-21

** Summary output for the GAM using extended rating 18 data **

```{r }
summary(gam18_rating)
```
** Summary output for the GAM using extended rating 19 data **

```{r}
summary(gam19_rating)
```

** Summary output for GAM using extended rating 20 data **
```{r, echo = FALSE}
summary(gam20_rating)

```

** Summary output for GAM using extended rating 21 data **
```{r echo = FALSE}

summary(gam21_rating)
```

** Summary GAM output using discrete measurement pairs during rating period 18 **
```{r echo = FALSE}
summary(gam18_measPair)
```

** Summary GAM output using discrete measurement pairs during rating period 19 **
```{r echo = FALSE}
summary(gam19_measPair)
```

** Summary GAM output using discrete measurement pairs during rating period 20 **
```{r echo = FALSE}
summary(gam20_measPair)
```

** Summary GAM output using discrete measurement pairs during rating period 21 **
```{r echo = FALSE}
summary(gam21_measPair)
```

** Summary GAM output using discrete measurement pairs during the period of analysis **
```{r echo = FALSE}
summary(gamPOA_measPair)
```


## Appendix 2. Full printout of all estimated state-space models.

** Results for MARSS with Q 'equalvarcov' and R mean specified variance of discrete measurements  ** 

```{r Model_05, echo = FALSE}

if ( file.exists( 'marss_fit_Q_equalvarcov_R_mean_qualifierCI.rds' )){
  marss_fit_Q_equalvarcov_R_mean_qualifierCI <- read_rds( 'marss_fit_Q_equalvarcov_R_mean_qualifierCI.rds' )
} else {
 marss_fit_Q_equalvarcov_R_mean_qualifierCI  <- MARSSparamCIs( marss_fit_Q_equalvarcov_R_mean_qualifier)
  
  write_rds(marss_fit_Q_equalvarcov_R_mean_qualifierCI, path = 'marss_fit_Q_equalvarcov_R_mean_qualifierCI.rds')
}
print( marss_fit_Q_equalvarcov_R_mean_qualifierCI )


```

** Results for MARSS model with Q 'diagonal and equal' and R mean specified variance **

```{r Model_03, echo = FALSE}

if ( file.exists( 'marss_fit_Q_ones_multiplier_R_mean_qualifierCI.rds' )){
  marss_fit_Q_ones_multiplier_R_mean_qualifierCI <- read_rds( 'marss_fit_Q_ones_multiplier_R_mean_qualifierCI.rds' )
} else {
 marss_fit_Q_ones_multiplier_R_mean_qualifierCI  <- MARSSparamCIs( marss_fit_Q_ones_multiplier_R_mean_qualifier)
  
  write_rds(marss_fit_Q_ones_multiplier_R_mean_qualifierCI, path = 'marss_fit_Q_ones_multiplier_R_mean_qualifierCI.rds')
}
print( marss_fit_Q_ones_multiplier_R_mean_qualifierCI )



```

** Results for MARSS model with Q diagonal with covariance multiplier and R mean specified variance of discrete measurements **

```{r Model_07, echo = FALSE}

if ( file.exists( 'marss_fit_Q_covar_multiplier_R_mean_qualifierCI.rds' )){
  marss_fit_Q_covar_multiplier_R_mean_qualifierCI <- read_rds( 'marss_fit_Q_covar_multiplier_R_mean_qualifierCI.rds' )
} else {
 marss_fit_Q_covar_multiplier_R_mean_qualifierCI  <- MARSSparamCIs( marss_fit_Q_covar_multiplier_R_mean_qualifier)
  
  write_rds(marss_fit_Q_covar_multiplier_R_mean_qualifierCI, path = 'marss_fit_Q_covar_multiplier_R_mean_qualifierCI.rds')
}
print( marss_fit_Q_covar_multiplier_R_mean_qualifierCI )

```

** Results for MARSS with Q 'unconstrained' and R mean specified variance of discrete measurements **

```{r Model_04, echo = FALSE}

if ( file.exists( 'marss_fit_Q_unconstrained_R_mean_qualifierCI.rds' )){
  marss_fit_Q_unconstrained_R_mean_qualifierCI <- read_rds( 'marss_fit_Q_unconstrained_R_mean_qualifierCI.rds' )
} else {
 marss_fit_Q_unconstrained_R_mean_qualifierCI  <- MARSSparamCIs( marss_fit_Q_unconstrained_R_mean_qualifier)
  
  write_rds(marss_fit_Q_unconstrained_R_mean_qualifierCI, path = 'marss_fit_Q_unconstrained_R_mean_qualifierCI.rds')
}
print( marss_fit_Q_unconstrained_R_mean_qualifierCI )

```

** Results for MARSS model with Q diagonal with covariance multiplier and R 'diagonal and equal' ** 

```{r Model_06, echo = FALSE}

if ( file.exists( 'marss_fit_Q_covar_multiplier_R_one_multiplierCI.rds' )){
  marss_fit_Q_covar_multiplier_R_one_multiplierCI <- read_rds( 'marss_fit_Q_covar_multiplier_R_one_multiplierCI.rds' )
} else {
 marss_fit_Q_covar_multiplier_R_one_multiplierCI  <- MARSSparamCIs( marss_fit_Q_covar_multiplier_R_one_multiplier)
  
  write_rds(marss_fit_Q_covar_multiplier_R_one_multiplierCI, path = 'marss_fit_Q_covar_multiplier_R_one_multiplierCI.rds')
}
print( marss_fit_Q_covar_multiplier_R_one_multiplierCI )


```

** Results for MARSS Model with Q 'diagonal and unequal' and R 'diagonal and equal' **
```{r Model_02, echo = FALSE}

if ( file.exists( 'marss_fit_Q_unequal_scalars_R_one_multiplierCI.rds' )){
  marss_fit_Q_unequal_scalars_R_one_multiplierCI <- read_rds( 'marss_fit_Q_unequal_scalars_R_one_multiplierCI.rds' )
} else {
 marss_fit_Q_unequal_scalars_R_one_multiplierCI  <- MARSSparamCIs( marss_fit_Q_unequal_scalars_R_one_multiplier)
  
  write_rds(marss_fit_Q_unequal_scalars_R_one_multiplierCI, path = 'marss_fit_Q_unequal_scalars_R_one_multiplierCI.rds')
}
print( marss_fit_Q_unequal_scalars_R_one_multiplierCI )

```

** Results for MARSS Model with Q = 'diagonal and equal' and R = 'diagonal and equal' **  

```{r Model_01, echo = FALSE}

if ( file.exists( 'marss_fit_Q_ones_multiplier_R_one_multiplierCI.rds' )){
  marss_fit_Q_ones_multiplier_R_one_multiplierCI <- read_rds( 'marss_fit_Q_ones_multiplier_R_one_multiplierCI.rds' )
} else {
 marss_fit_Q_ones_multiplier_R_one_multiplierCI  <- MARSSparamCIs( marss_fit_Q_ones_multiplier_R_one_multiplier)
  
  write_rds(marss_fit_Q_ones_multiplier_R_one_multiplierCI, path = 'marss_fit_Q_ones_multiplier_R_one_multiplierCI.rds')
}
print( marss_fit_Q_ones_multiplier_R_one_multiplierCI )

```


** Results for MARSS Model with Q diagonal with scalar covariance multiplier and R time varying specified measurement variance**  

```{r Model_09, echo = FALSE}

if ( file.exists( 'marss_fit_Q_covar_multiplier_R_series_qualifierCI.rds' )){
  marss_fit_Q_covar_multiplier_R_series_qualifierCI <- read_rds( 'marss_fit_Q_covar_multiplier_R_series_qualifierCI.rds' )
} else {
 marss_fit_Q_covar_multiplier_R_series_qualifierCI  <- MARSSparamCIs( marss_fit_Q_covar_multiplier_R_series_qualifier)
  
  write_rds(marss_fit_Q_covar_multiplier_R_series_qualifierCI, path = 'marss_fit_Q_covar_multiplier_R_series_qualifierCI.rds')
}
print( marss_fit_Q_covar_multiplier_R_series_qualifierCI )

```


** Results for MARSS Model with Q 'diagonal and equal', and R time varying specified measurement variance **  

```{r Model_08, echo = FALSE}

if ( file.exists( 'marss_fit_Q_ones_multiplier_R_series_qualifierCI.rds' )){
  marss_fit_Q_ones_multiplier_R_series_qualifierCI <- read_rds( 'marss_fit_Q_ones_multiplier_R_series_qualifierCI.rds' )
} else {
 marss_fit_Q_ones_multiplier_R_series_qualifierCI  <- MARSSparamCIs( marss_fit_Q_ones_multiplier_R_series_qualifier)
  
  write_rds(marss_fit_Q_ones_multiplier_R_series_qualifierCI, path = 'marss_fit_Q_ones_multiplier_R_series_qualifierCI.rds')
}
print( marss_fit_Q_ones_multiplier_R_series_qualifierCI )

```

## References Cited



